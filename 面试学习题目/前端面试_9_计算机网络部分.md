----



-----

## 1. 请问你了解OSI七层模型吗？

**OSI**（Open System Interconnect），即**开放式系统互联**。 一般都叫OSI参考模型，是ISO（国际标准化组织）组织在1985年研究的网络互连模型。ISO为了更好的使网络应用更为普及，推出了OSI参考模型。其含义就是推荐所有公司使用这个规范来控制网络。这样所有公司都有相同的规范，就能互联了。
**OSI定义了网络互连的七层框架**（物理层、数据链路层、网络层、传输层、会话层、表示层、应用层），即ISO开放互连系统参考模型。

![img](E:\pogject\学习笔记\image\http\D6A70DA7466DF3865BABC8FDAA316E4C)

### 应用层

OSI参考模型中最靠近用户的一层，是**为计算机用户提供应用接口，也为用户直接提供各种网络服务**。我们常见应用层的网络服务协议有：**HTTP，HTTPS，FTP，POP3、SMTP等。**

作用：它是与其他计算机进行通信的应用，它是对应应用程序的通信服务的。各种应用软件，包括web应用。

协议：DNS、FTP、HTTP、SMTP、TELNET、IRC、WHOIS

HTTP（Hyper text Transfer Protocol）协议：超文本传输协议使用TCP的80端口

FTP（File Transfer Protocol）文本传输协议

SMTP（Simple Mail Transfer Protocol）简单邮件传输协议，TCP是我25端口用户发邮件。

POP3（Post Office Protocol version3）邮局协议版本3，TCP的110号端口，用于收邮件的。

DNS（Domain Name System）域名解析协议。使用TCP和UDP的53号端口，作用是把www的域名解析成IP地址。



### 表示层

**表示层提供各种用于应用层数据的编码和转换功能**,确保一个系统的应用层发送的数据能被另一个系统的应用层识别。如果必要，该层可提供一种标准表示形式，用于将计算机内部的多种数据格式转换成通信中采用的标准表示形式。**数据压缩和加密**也是表示层可提供的转换功能之一。

作用：这一层的主要作用是定义数据格式和加密。



### 会话层

会话层就是**负责建立、管理和终止表示层实体之间的通信会话**。该层的通信由不同设备中的应用程序之间的服务请求和响应组成。

作用：控制应用程序的会话能力，它定义了一段会话的开始、控制和结束，包括对多个双向消息的控制和管理，以便在只完成一部分消息时可以通知应用。



### 传输层

传输层建立了主机端到端的链接，传输层的作用是**为上层协议提供端到端的可靠和透明的数据传输服务**，包括处理差错控制和流量控制等问题。该层向高层屏蔽了下层数据通信的细节，使高层用户看到的只是在两个传输实体间的一条主机到主机的、可由用户控制和设定的、可靠的数据通路。我们通常说的，**TCP UDP就是在这一层。端口号既是这里的“端”。**

作用：对差错恢复协议和无差错恢复协议的选择，对同一主机上不同数据流的输入进行复用，对数据包进行重新排序。是最关键的一层，是唯一负责整体的数据传输和数据控制的。对上三层提供可靠的传输服务，对网络层提供可靠的目的地信息。在这一层数据的单位被称为数据段。

协议：TCP、UDP等



### 网络层

本层**通过IP寻址来建立两个节点之间的连接**，为源端的运输层送来的分组，选择合适的路由和交换节点，正确无误地按照地址传送给目的端的运输层。就是通常说的**IP层**。这一层就是我们经常说的IP协议层。IP协议是Internet的基础。

作用：主要负责寻找地址和路由选择，网络层还可以实现阻塞控制、网际互联等。

协议：IP、IPX、RIP、OSPF等



### 数据链路层 

将比特组合成字节,再将字节组合成帧,使用链路层地址 (以太网使用MAC地址)来访问介质,并进行差错检测。

数据链路层又分为2个子层：**逻辑链路控制**子层（LLC）和**媒体访问控制**子层（MAC）。

 MAC子层处理CSMA/CD算法、数据出错校验、成帧等；LLC子层定义了一些字段使上次协议能共享数据链路层。 在实际使用中，LLC子层并非必需的。

作用：负责物理层面上的互联的、节点间的通信传输；该层的作用包括：物理地址寻址、数据的成帧、流量控制、数据的检错、重发等。在这一层，数据的单位称为帧（frame）

协议：ARP、RARP、SDLC、HDLC、PPP、STP、帧中继等



### 物理层   

**实际最终信号的传输是通过物理层实现的**。通过物理介质传输比特流。规定了电平、速度和电缆针脚。常用设备有（各种物理设备）集线器、中继器、调制解调器、网线、双绞线、同轴电缆。这些都是物理层的传输介质。

作用：负责0、1 比特流（0/1序列）与电压的高低、逛的闪灭之间的转换 规定了激活、维持、关闭通信端点之间的机械特性、电气特性、功能特性以及过程特性；该层为上层协议提供了一个传输数据的物理媒体。在这一层，数据的单位称为比特（bit）。

典型规范：EIA/TIA RS-232、EIA/TIA RS-449、V.35、RJ-45、fddi令牌环网等



---

## 2. 请问你了解TCP/IP五层协议吗？它与OSI七层模型有什么关系吗？

**TCP/IP协议**包含四个概念层，其中有三层对应于OSI模型中的相应层，TCP/IP协议族并不包含物理层和数据链路层，因此它不能独立完成整个计算机网络系统的功能，必须与许多其他的协议协同工作。

- **网络接口层**

用于协作IP数据在已有网络介质上传输的协议。实际上TCP/IP标准**并不**定义与ISO数据链路层和物理层相对应的功能。相反，它定义像**地址解析协议**(Address Resolution Protocol,ARP)这样的协议，**提供TCP/IP协议的数据结构和实际物理硬件之间的接口。**

- **网络层**

对应于OSI七层模型的**网络层**。本层包含IP协议、RIP协议(Routing Information Protocol，路由信息协议)，负责数据的包装、寻址和路由。同时还包含网间控制报文协议(Internet Control Message Protocol,ICMP)用来提供网络诊断信息。

- **传输层**

对应于OSI七层模型的**传输层**，它提供两种端到端的通信服务。其中TCP协议(Transmission Control Protocol)提供可靠的数据流运输服务，UDP协议(Use Datagram Protocol)提供不可靠的用户数据报服务。

- **应用层**

对应于OSI七层模型的**应用层、表达层与会话层**。因特网的应用层协议包括Finger、Whois、FTP(文件传输协议)、Gopher、HTTP(超文本传输协议)、Telent(远程终端协议)、SMTP(简单邮件传送协议)、IRC(因特网中继会话)、NNTP（网络新闻传输协议）等。

TCP/IP五层协议与OSI的七层模型对应关系如下：

![img](E:\pogject\学习笔记\image\http\E3C7704B2554F5FA5553E2FF7A4E7F55)





----

## 3 请问你能阐述下TCP与UDP的区别吗？

TCP和UDP是OSI模型中的传输层中的协议。TCP提供可靠的通信传输，而UDP则常被用于让广播和细节控制交给应用的通信传输。

- TCP是一种面向连接的、可靠的、基于**字节流**的传输层通信协议，是专门为了**在不可靠的网络中提供一个可靠的端对端字节流**而设计的，面向**字节流**。
- UDP（用户数据报协议）是iso参考模型中一种**无连接**的传输层协议，提供**简单不可靠的非连接传输层服务**，面向**报文**

**TCP(传输控制协议)**：充分实现了数据传输时各种控制功能，**可以进行丢包的重发控制，还可以对次序乱掉的分包进行顺序控制**。而这些在UDP都没有。此外，TCP作为一种面向有连接的协议，只有在确认通信对端存在时才会发送数据，从而可以控制通信流量的浪费。TCP通过**检验和**、**序列号**、**确认应答**、**重发控制**、**连接管理**以及**窗口控制**等机制实现可靠性传输。

**UDP（用户数据报协议）**：不提供复杂的控制机制，利用IP提供面向无连接的通信服务。并且它是将应用程序发来的数据在收到的那一刻，立刻按照原样发送到网络上的一种机制。即使是出现网络拥堵的情况下，UDP也无法进行流量控制等避免网络拥塞的行为。此外，传输途中如果出现了丢包，UDP也不负责重发。

TCP与UDP区别：

- (1) **是否连接**：TCP面向连接（如打电话要先拨号建立连接），UDP是**无连接**的，即发送数据之前不需要建立连接
- (2) **可靠性**：TCP提供可靠的服务。通过TCP连接传送的数据，无差错，不丢失，不重复，且按序到达，**UDP尽最大努力交付**，即不保证可靠交付
- (3) **数据流**： TCP面向**字节流**，实际上是TCP把数据看成一连串无结构的字节流；UDP是面向**报文**的，UDP没有拥塞控制，**因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如IP电话，实时视频会议等）**

- (4) **是否多端**： 每一条TCP连接只能是**点到点的**；UDP支持一对一，一对多，多对一和多对多的交互通信

- (5) **首部开销**： TCP首部开销**20字节**；UDP的首部开销小，只有**8个字节**。TCP在IP协议的基础上添加了序号机制、确认机制、超时重传机制等，保证了传输的可靠性，不会出现丢包或乱序，**而UDP有丢包**，**故TCP开销大**，UDP开销较小

- (6) **信道**： TCP的逻辑通信信道是**全双工的可靠信道**，UDP则是不可靠信道
- (7) **安全性**：由于TCP是连接的通信，需要有三次握手、重新确认等连接过程，会有延时，实时性差，同时过程复杂，**也使其易于攻击**；UDP没有建立连接的过程，因而实时性较强，**也稍安全**

TCP与UDP的区别

1、基于连接与无连接；2、对系统资源的要求（TCP较多，UDP少）；3、UDP程序结构较简单；4、流模式与数据报模式；5、TCP保证数据正确性，UDP可能丢包；6、TCP保证数据顺序，UDP不保证。

**应用场景选择**

- 对**实时性要求高和高速传输**的场合下使用UDP; 在可靠性要求低，**追求效率**的情况下使用UDP;
- 需要**传输大量数据且对可靠性要求高**的情况下使用TCP

UDP 常用于以下几个方面：

- 包总量较少的通信（DNS、SNMP等）；
- 视频、音频等多媒体通信（即时通信）；
- 限定于 LAN 等特定网络中的应用通信；
- 广播通信（广播、多播）。



---

## 4 请问你能阐述下TCP三次握手与四次挥手的过程吗？

### TCP三次握手

### ① 三次握手过程详解

三次握手的原文是 `three-way handshake`，整个名词的可以翻译为：**需要三个步骤才能建立握手/连接的机制**。当然，三次握手也可以叫 `three-message handshake`，**通过三条消息来建立的握手/连接**。

进行三次握手的**主要作用**就是为了确认双方的**接收能力和发送能力**是否正常、指定自己的 **初始化序列号(Init Sequense Number, `ISN`)** 为后面的可靠性传输做准备。

三次握手过程如下图：

![img](E:\pogject\学习笔记\image\http\TCP三次握手)

回顾一下图中字符的含义：

- `SYN`：连接请求/接收 报文段
- `seq`：发送的第一个字节的序号
- `ACK`：确认报文段
- `ack`：确认号。**希望收到的下一个数据的第一个字节的序号**

**刚开始客户端处于 `Closed` 的状态，而服务端处于 `Listen` 状态**：

> CLOSED ：没有任何连接状态
>
> `LISTEN `：侦听来自远方 TCP 端口的连接请求

**1）第一次握手**：客户端向服务端发送一个 SYN 报文（SYN = 1），并指明客户端的初始化序列号 ISN(x)，即图中的 seq = x，表示本报文段所发送的数据的第一个字节的序号。此时客户端处于 `SYN_Send` 状态。

> `SYN-SENT` ：在发送连接请求后等待匹配的连接请求

**2）第二次握手**：服务器收到客户端的 SYN 报文之后，会发送 SYN 报文作为应答（SYN = 1），并且指定自己的初始化序列号 ISN(y)，即图中的 seq = y。同时会把客户端的 ISN + 1 作为确认号 ack 的值，表示已经收到了客户端发来的的 SYN 报文，希望收到的下一个数据的第一个字节的序号是 x + 1，此时服务器处于 `SYN_REVD` 的状态。

> `SYN-RECEIVED`：在收到和发送一个连接请求后等待对连接请求的确认

**3）第三次握手**：客户端收到服务器端响应的 SYN 报文之后，会发送一个 ACK 报文，也是一样把服务器的 ISN + 1 作为 ack 的值，表示已经收到了服务端发来的的 SYN 报文，希望收到的下一个数据的第一个字节的序号是 y + 1，并指明此时客户端的序列号 seq = x + 1（初始为 seq = x，所以第二个报文段要 +1），此时客户端处于 `Establised` 状态。

服务器收到 ACK 报文之后，也处于 `Establised 状态`，至此，双方建立起了 TCP 连接。

> `ESTABLISHED`：代表一个打开的连接，数据可以传送给用户

### ② 为什么要三次握手

三次握手的目的是**建立可靠的通信信道**，说到通讯，简单来说就是数据的发送与接收，而三次握手最主要的目的就是**双方确认自己与对方的发送与接收是正常的**。

只有经过三次握手才能确认双发的收发功能都正常，缺一不可：

- 第一次握手（客户端发送 SYN 报文给服务器，服务器接收该报文）：

  客户端什么都不能确认；

  **服务器确认了对方发送正常，自己接收正常**

  

- 第二次握手（服务器响应 SYN 报文给客户端，客户端接收该报文）：

  客户端确认了：**自己发送、接收正常，对方发送、接收正常；**

  服务器确认了：对方发送正常，自己接收正常

  

- 第三次握手（客户端发送 ACK 报文给服务器）：

  客户端确认了：自己发送、接收正常，对方发送、接收正常；

  服务器确认了：**自己发送**、接收正常，对方发送、**接收正常**



### ③ ISN (Initial Sequence Number) 是固定的吗

三次握手的其中一个**重要功能**是客户端和服务端**交换 ISN**(Initial Sequence Number)，**以便让对方知道接下来接收数据的时候如何按序列号组装数据。**

当一端为建立连接而发送它的 SYN 时，它会为连接选择一个初始序号。ISN 随时间而变化，**因此每个连接都将具有不同的 ISN**。如果 ISN **是固定的，攻击者很容易猜出后续的确认号**，因此 ISN 是动态生成的。

### ④ 三次握手过程中可以携带数据吗

第三次握手的时候，是可以携带数据的。但是，**第一次、第二次握手绝对不可以携带数据**

假如第一次握手可以携带数据的话，如果有人要恶意攻击服务器，那他每次都在第一次握手中的 SYN 报文中放入大量的数据，然后疯狂重复发 SYN 报文的话（因为攻击者根本就不用管服务器的接收、发送能力是否正常，它就是要攻击你），这会让服务器花费很多时间、内存空间来接收这些报文。

**简单的记忆就是，请求连接/接收 即 `SYN = 1` 的时候不能携带数据**

而对于第三次的话，此时客户端已经处于 `ESTABLISHED` 状态。对于客户端来说，他已经建立起连接了，并且也已经知道服务器的接收、发送能力是正常的了，所以当然能正常发送/携带数据了。

### ⑤ 半连接队列

服务器第一次收到客户端的 SYN 之后，就会处于 `SYN_RCVD` 状态，此时双方还没有完全建立其连接，服务器会把这种状态下的请求连接放在一个队列里，我们把这种队列称之为**半连接队列**。

当然还有一个**全连接队列**，完成三次握手后建立起的连接就会放在全连接队列中。如果队列满了就有可能会出现丢包现象。

### ⑥ SYN 洪泛攻击

SYN 攻击就是 **Client 在短时间内伪造大量不存在的 IP 地址，并向 Server 不断地发送 SYN 包**，Server 则回复确认包，并等待 Client 确认，由于源地址不存在，因此 Server 需要不断重发直至超时，**这些伪造的 SYN 包将长时间占用半连接队列，导致正常的 SYN 请求因为队列满而被丢弃，从而引起网络拥塞甚至系统瘫痪。**

### ⑦ 如果第三次握手丢失了，客户端服务端会如何处理

服务器发送完 SYN-ACK 包，如果未收到客户端响应的确认包，也即第三次握手丢失。**那么服务器就会进行首次重传，若等待一段时间仍未收到客户确认包，就进行第二次重传**。如果**重传次数超过系统规定的最大重传次数，则系统将该连接信息从半连接队列中删除**。

注意，每次重传等待的时间不一定相同，一般会是指数增长，例如间隔时间为 1s，2s，4s，8s…



---

### TCP 四次挥手释放连接

### ① 四次挥手过程详解

建立一个 TCP 连接需要三次握手，而终止一个 TCP 连接要经过四次挥手（也有将四次挥手叫做四次握手的）。这是由于 TCP 的**半关闭**（half-close）特性造成的，TCP 提供了**连接的一端在结束它的发送后还能接收来自另一端数据的能力。**

TCP 连接的释放**需要发送四个包**（执行四个步骤），因此称为四次挥手(`Four-way handshake`)，**客户端或服务端均可主动发起挥手动作**。

![img](E:\pogject\学习笔记\image\js\TCP四次挥手)

回顾一下上图中符号的意思：

- `FIN` ：连接终止位
- `seq`：发送的第一个字节的序号
- `ACK`：确认报文段
- `ack`：确认号。希望收到的下一个数据的第一个字节的序号

刚开始双方都处于`ESTABLISHED` 状态，假设是客户端先发起关闭请求。四次挥手的过程如下：

**1）第一次挥手**：客户端发送一个 FIN 报文（请求连接终止：FIN = 1），报文中会指定一个序列号 seq = u。并**停止再发送数据，主动关闭 TCP 连接**。此时客户端处于 `FIN_WAIT1` 状态，等待服务端的确认。

> `FIN-WAIT-1` - 等待远程TCP的连接中断请求，或先前的连接中断请求的确认；

**2）第二次挥手**：服务端收到 FIN 之后，会发送 ACK 报文，且把客户端的序号值 +1 作为 ACK 报文的序列号值，表明已经收到客户端的报文了，此时服务端处于 `CLOSE_WAIT` 状态。

> `CLOSE-WAIT` - 等待从本地用户发来的连接中断请求；

**此时的 TCP 处于半关闭状态，客户端到服务端的连接释放**。客户端收到服务端的确认后，进入`FIN_WAIT2`（终止等待 2）状态，等待服务端发出的连接释放报文段。

> `FIN-WAIT-2` - 从远程TCP等待连接中断请求；

**3）第三次挥手**：如果**服务端**也想断开连接了（没有要向客户端发出的数据），和客户端的第一次挥手一样，发送 FIN 报文，且指定一个序列号。此时服务端处于 `LAST_ACK` 的状态，等待客户端的确认。

> `LAST-ACK` - 等待原来发向远程TCP的连接中断请求的确认；

**4）第四次挥手**：客户端收到 FIN 之后，一样发送一个 ACK 报文作为应答（ack = w+1），且把服务端的序列值 +1 作为自己 ACK 报文的序号值（seq=u+1），此时客户端处于 **`TIME_WAIT` （时间等待）状态**。

> `TIME-WAIT` - 等待足够的时间以确保远程TCP接收到连接中断请求的确认；

> 注意 ！！！这个时候由服务端到客户端的 TCP 连接并未释放掉，**需要经过时间等待计时器设置的时间 2MSL（一个报文的来回时间） 后才会进入 `CLOSED` 状态**（这样做的目的是确保服务端收到自己的 ACK 报文。如果服务端在规定时间内没有收到客户端发来的 ACK 报文的话，服务端会重新发送 FIN 报文给客户端，客户端再次收到 FIN 报文之后，就知道之前的 ACK 报文丢失了，然后再次发送 ACK 报文给服务端）。服务端收到 ACK 报文之后，就关闭连接了，处于 `CLOSED` 状态。

### ② 为什么要四次挥手

由于 TCP 的**半关闭**（half-close）特性，**TCP 提供了连接的一端在结束它的发送后还能接收来自另一端数据的能力。**

任何一方都可以在数据传送结束后发出连接释放的通知，待对方确认后进入**半关闭状态**。当另一方也没有数据再发送的时候，则发出连接释放通知，对方确认后就**完全关闭**了TCP连接。

**通俗的来说，两次握手就可以释放一端到另一端的 TCP 连接，完全释放连接一共需要四次握手**。

举个例子：A 和 B 打电话，通话即将结束后，A 说 “我没啥要说的了”，B 回答 “我知道了”，于是 A 向 B 的连接释放了。但是 B 可能还会有要说的话，于是 B 可能又巴拉巴拉说了一通，最后 B 说“我说完了”，A 回答“知道了”，于是 B 向 A 的连接释放了，这样整个通话就结束了。

---

### 为什么建立连接是三次握手，而关闭连接却是四次挥手呢？

这是因为服务端在LISTEN状态下，**收到建立连接请求的SYN报文后，把ACK和SYN放在一个报文里发送给客户端**。

而关闭连接时，当收到对方的FIN报文时，**仅仅表示对方不再发送数据了但是还能接收数据**，己方是否现在关闭发送数据通道，需要上层应用来决定，因此，己方ACK和FIN一般都会分开发送。

---

## 5. tcp三次握手，为什么需要三次

两个目的：

1. 确保建立可靠连接
2. 避免资源浪费

**三次握手的目的是 "为了防止已经失效的连接请求报文段突然又传到服务端，因而产生错"**，这种情况是：一端(client)A发出去的第一个连接请求报文并没有丢失，而是因为某些未知的原因在某个网络节点上发生滞留，导致延迟到连接释放以后的某个时间才到达另一端(server)B。本来这是一个早已失效的报文段，但是B收到此失效的报文之后，会误认为是A再次发出的一个新的连接请求，于是B端就向A又发出确认报文，表示同意建立连接。

如果不采用“三次握手”，那么只要B端发出确认报文就会认为新的连接已经建立了，但是A端并没有发出建立连接的请求，因此不会去向B端发送数据，B端没有收到数据就会一直等待，这样B端就会白白浪费掉很多资源。如果采用“三次握手”的话就不会出现这种情况，**B端收到一个过时失效的报文段之后，向A端发出确认，此时A并没有要求建立连接，所以就不会向B端发送确认**，这个时候B端也能够知道连接没有建立

建立连接的过程是利用客户服务器模式，假设主机A为客户端，主机B为服务器端。

采用三次握手是为了防止失效的连接请求报文段突然又传送到主机B，因而产生错误。

失效的连接请求报文段是指：主机A发出的连接请求没有收到主机B的确认，于是经过一段时间后，主机A又重新向主机B发送连接请求，且建立成功，顺序完成数据传输。

考虑这样一种特殊情况，主机A第一次发送的连接请求并没有丢失，而是因为网络节点导致延迟达到主机B，主机B以为是主机A又发起的新连接，于是主机B同意连接，并向主机A发回确认，但是此时主机A根本不会理会，主机B就一直在等待主机A发送数据，导致主机B的资源浪费。

采用两次握手不行，原因就是上面说的失效的连接请求的特殊情况。

而在三次握手中，client和server都有一个发syn和收ack的过程，双方都是发后能收，表明通信则准备工作OK。

为什么不是四次握手呢？

因为通信不可能100%可靠，而上面的三次握手已经做好了通信的准备工作，再增加握手，并不能显著提高可靠性，而且也没有必要。



---

## 6 请问TCP如何保证数据的可靠传输的呢？

TCP提供一种面向连接的、可靠的字节流服务。其中，**面向连接**意味着两个使用TCP的应用（通常是一个客户和一个服务器）在彼此交换数据之前必须先建立一个TCP连接。在一个TCP连接中，仅有两方进行彼此通信；而**字节流服务**意味着两个应用程序通过TCP链接交换8bit字节构成的字节流，**TCP不在字节流中插入记录标识符。**

TCP通过以下方式保证数据传输的可靠性：

**数据包校验**：目的是检测数据在传输过程中的任何变化，若校验出包有错，则丢弃报文段并且不给出响应，这时TCP发送数据端超时后会重发数据

**对失序数据包重排序**：既然TCP报文段作为IP数据包来传输，而IP数据包的到达可能会失序，因此TCP报文段的到达也可能会失序。TCP将对失序数据进行重新排序，然后才交给应用层

**丢弃重复数据**：对于重复数据，能够丢弃重复数据

**应答机制**：当TCP收到发自TCP连接另一端的数据，**它将发送一个确认**。这个确认不是立即发送，通常将推迟几分之一秒

**超时重发**：当TCP发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。**如果不能及时收到一个确认，将重发这个报文段**

**流量控制**：TCP连接的每一方都有固定大小的缓冲空间。**TCP的接收端只允许另一端发送接收端缓冲区所能接纳的数据**，这可以防止较快主机致使较慢主机的缓冲区溢出，这就是流量控制。TCP使用的**流量控制协议**是**可变大小的滑动窗口协议**



----

## 7. 请问TCP如何拥塞控制呢？

**防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载**。拥塞控制所要做的都有一个**前提**：网络能够承受现有的网络负荷。拥塞控制是一个全局性的过程，涉及到所有的主机、路由器，以及与降低网络传输性能有关的所有因素。

拥塞控制代价：**需要获得网络内部流量分布的信息**。在实施拥塞控制之前，还需要在结点之间交换信息和各种命令，以便选择控制的策略和实施控制。**这样就产生了额外的开销**。拥塞控制还需要将一些资源分配给各个用户单独使用，**使得网络资源不能更好地实现共享**。

几种常见**拥塞控制方法**：

慢开始(slow-start )、拥塞避免(congestion avoidance )、快重传( fastretransmit )和快恢复( fastrecovery )。



---

## 8. 请问你了解超文本传送协议HTTP吗？

###  HTTP协议

HTTP是一个属于**应用层**的面向对象的协议，由于其简捷、快速的方式，适用于分布式超媒体信息系统。HTTP协议的主要特点可概括如下：

- **支持客户/服务器模式**。
- **简单快速**：客户向服务器请求服务时，只需传送请求方法和路径。请求方法常用的有GET、HEAD、POST。每种方法规定了客户与服务器联系的类型不同。由于HTTP协议简单，使得HTTP服务器的程序规模小，因而通信速度很快。
- **灵活**：HTTP允许传输任意类型的数据对象。正在传输的类型由Content-Type加以标记。
- **无连接**：无连接的**含义是限制每次连接只处理一个请求**。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。
- **无状态**：HTTP协议是无状态协议。无状态是**指协议对于事务处理没有记忆能力**。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。**另一方面，在服务器不需要先前信息时它的应答就较快。**

---

###  HTTP协议的优点和缺点

**优点**：

- 支持客户端/服务器模式
- **简单快速**：客户向服务器请求服务时，只需传送请求方法和路径。由于 HTTP 协议简单，使得 HTTP 服务器的程序规模小，因而通信速度很快。
- **无连接**：无连接的**含义是限制每次链接只处理一个请求**。服务器处理完客户的请求，并收到客户的应答后，即断开链接，采用这种方式可以节省传输时间。
- **无状态**：HTTP 协议是无状态协议，这里的**状态是指通信过程的上下文信息**。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能会导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就比较快。
- **灵活**：HTTP 允许传输任意类型的数据对象。正在传输的类型由 Content-Type 加以标记。

HTTP协议具有以下**缺点**：

- **无状态：** HTTP 是一个无状态的协议，HTTP 服务器不会保存关于客户的任何信息。
- **明文传输：** 协议中的报文使用的是文本形式，这就直接暴露给外界，不安全。
- **不安全**  （1）通信使用明文（不加密），内容可能会被窃听 （2）不验证通信方的身份，因此有可能遭遇伪装 （3）无法证明报文的完整性，所以有可能已遭篡改

----

###  HTTP 1.0和 HTTP 1.1 之间有哪些区别？

- **连接方面** 的区别，http1.1 默认使用持久连接，而 http1.0 默认使用非持久连接。http1.1 通过使用持久连接来使多个 http 请求复用同一个 TCP 连接，以此来避免使用非持久连接时每次需要建立连接的时延。
- **资源请求方面** 的区别，在 http1.0 中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，http1.1 则在请求头引入了 range 头域，它允许只请求资源的某个部分，**即返回码是 206**（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。
- **缓存方面** 的区别，在 http1.0 中主要使用 header 里的 If-Modified-Since,Expires 来做为缓存判断的标准，http1.1 则引入了更多的缓存控制策略例如 Etag、If-Unmodified-Since、If-Match、If-None-Match 等更多可供选择的缓存头来控制缓存策略。
- http1.1 中还**新增了 host 字段**，用来指定服务器的域名。http1.0 中认为每台服务器都绑定一个唯一的 IP 地址，因此，请求消息中的 URL 并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机，并且它们共享一个IP地址。因此有了 host 字段，就可以将请求发往同一台服务器上的不同网站。
- http1.1 相对于 http1.0 还新增了很多**请求方法**，如 PUT、HEAD、OPTIONS 等。



---

### http1.x 和http2.x区别

http1.x 和http2.x主要有以下4个区别：

1. HTTP2使用的是二进制传送，HTTP1.X是文本（字符串）传送。

   二进制传送的单位是帧和流。**帧组成了流，同时流还有流ID标示**

2. HTTP2支持多路复用

   **因为有流ID，所以通过同一个http请求实现多个http请求传输变成了可能**，可以通过流ID来标示究竟是哪个流从而定位到是哪个http请求

3. HTTP2头部压缩

   HTTP2通过gzip和compress压缩头部然后再发送，同时客户端和服务器端同时维护一张**头信息表**，所有字段都记录在这张表中，这样后面**每次传输只需要传输表里面的索引Id就行，通过索引ID查询表头的值**

4. HTTP2支持服务器推送

   HTTP2支持在未经客户端许可的情况下，主动向客户端推送内容

###  HTTP 1.1和 HTTP 2.0 的区别

- **二进制协议**：HTTP/2 是一个二进制协议。在 HTTP/1.1 版中，报文的头信息必须是文本（ASCII 编码），数据体可以是文本，也可以是 二进制。HTTP/2 则是一个彻底的二进制协议，头信息和数据体都是二进制，并且统称为”帧”，可以分为头信息帧和数据帧。 帧的概念是它实现多路复用的基础。
- **多路复用：** HTTP/2 实现了多路复用，HTTP/2 仍然复用 TCP 连接，但是在一个连接里，客户端和服务器都可以同时发送多个请求或回 应，而且不用按照顺序一一发送，这样就避免了”队头堵塞”的问题。
- **数据流：** HTTP/2 使用了数据流的概念，因为 HTTP/2 的数据包是不按顺序发送的，同一个连接里面连续的数据包，可能属于不同的 请求。因此，必须要对数据包做标记，指出它属于哪个请求。HTTP/2 将每个请求或回应的所有数据包，称为一个数据流。每 个数据流都有一个独一无二的编号。数据包发送的时候，都必须标记数据流 ID ，用来区分它属于哪个数据流。
- **头信息压缩：** HTTP/2 实现了头信息压缩，由于 HTTP 1.1 协议不带有状态，每次请求都必须附上所有信息。所以，请求的很多字段都是 重复的，比如 Cookie 和 User Agent ，一模一样的内容，每次请求都必须附带，这会浪费很多带宽，也影响速度。HTTP/2 对这一点做了优化，引入了头信息压缩机制。一方面，头信息使用 gzip 或 compress 压缩后再发送；另一方面， 客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引 号，这样就能提高速度了。
- **服务器推送：** HTTP/2 允许服务器未经请求，主动向客户端发送资源，这叫做服务器推送。使用服务器推送，提前给客户端推送必要的资源 ，这样就可以相对减少一些延迟时间。这里需要注意的是 http2 下服务器主动推送的是静态资源，和 WebSocket 以及使用 SSE 等方式向客户端发送即时数据的推送是不同的。



---

## 9. 请问HTTP和HTTPS两者有哪些区别？

### HTTP和HTTPS的基本概念

HTTP：HTTP协议是超文本传输协议，是互联网上应用最为广泛的一种网络协议，是一个客户端和服务器端请求和应答的标准（TCP），用于从WWW服务器传输超文本到本地浏览器的传输协议，它可以使浏览器更加高效，使网络传输减少。

HTTPS：HTTPS是安全的超文本传输协议，是安全版的HTTP协议，使用**安全套接字层(SSL)**进行信息交换，是以安全为目标的HTTP通道，**即HTTP下加入SSL层**，HTTPS的安全基础是SSL（Secure Sockets Layer），因此加密的详细内容就需要SSL。

HTTPS协议的主要作用可以分为两种：一种是**建立一个信息安全通道，来保证数据传输的安全**；另一种就是**确认网站的真实性**。

HTTPS协议主要针对解决**HTTP协议以下不足**：

- 1、通信使用明文（不加密），内容可能会被窃听
- 2、不验证通信方身份，因此可能遭遇伪装
- 3、无法证明报文的完整性（即准确性），所以可能已遭篡改

  **HTTP+加密+认证+完整性保护 = HTTPS**，HTTP端口 **80**， HTTPS端口**443**

  HTTPS采用**对称加密**、SSL位于应用层与传输层TCP之间，原本数据由应用层直接交由传输层处理，**现在会经过SSL加密再进行传输**。



### HTTP与HTTPS区别

HTTPS和HTTP的区别主要如下：

- 1、https协议**需要到ca申请证书**，一般免费证书较少，因而需要一定费用。
- 2、http是超文本传输协议，信息是**明文传输**，https则是具有安全性的ssl加密传输协议。
- 3、http和https使用的是**完全不同的连接方式**，**用的端口也不一样**，前者是**80**，后者是**443**。
- 4、http的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。

注意：HTTPS也不是绝对安全的，**针对SSL的中间人攻击**方式主要有两类，分别是**SSL劫持攻击**和**SSL剥离攻击**。

SSL劫持攻击就是 SSL证书欺骗攻击，将自己接入到客户端和目标网站之间； 在传输过程中伪造服务器的证书，将服务器的公钥替换成自己的公钥。



----

## 10. 简单说下你对 HTTP2 的理解

### HTTP/1.1 存在的问题

- TCP 连接数限制

对于同一个域名，浏览器最多只能同时创建 6~8 个 TCP 连接 (不同浏览器不一样)。为了解决数量限制，出现了 **域名分片 技术**，其实就是资源分域，将资源放在不同域名下 (比如二级子域名下)，这样就可以针对不同域名创建连接并请求，以一种讨巧的方式突破限制，但是滥用此技术也会造成很多问题，比如每个 TCP 连接本身需要经过 DNS 查询、三步握手、慢启动等，还占用额外的 CPU 和内存，对于服务器来说过多连接也容易造成网络拥挤、交通阻塞等，对于移动端来说问题更明显。

- 线头阻塞 (Head Of Line Blocking) 问题

每个 TCP 连接同时只能处理一个请求 - 响应，浏览器按 FIFO 原则处理请求，如果上一个响应没返回，后续请求 - 响应都会受阻。为了解决此问题，出现了 **管线化 - pipelining 技术**，但是管线化存在诸多问题，比如第一个响应慢还是会阻塞后续响应、服务器为了按序返回相应需要缓存多个响应占用更多资源、浏览器中途断连重试服务器可能得重新处理多个请求、还有必须客户端 - 代理 - 服务器都支持管线化。

- Header 内容多，而且每次请求 Header 不会变化太多，没有相应的压缩传输优化方案
- 为了尽可能减少请求数，需要做合并文件、雪碧图、资源内联等优化工作，但是这无疑造成了单个请求内容变大延迟变高的问题，且内嵌的资源不能有效地使用缓存机制
- 明文传输不安全

### HTTP2 的优势

#### 二进制分帧层 (Binary Framing Layer)

帧是数据传输的最小单位，以二进制传输代替原本的明文传输，原本的报文消息被划分为更小的数据帧。

#### 多路复用 (MultiPlexing)

在一个 TCP 连接上，我们可以向对方不断发送帧，每帧的 stream identifier 的标明这一帧属于哪个流，然后在对方接收时，根据 stream identifier 拼接每个流的所有帧组成一整块数据。

把 HTTP/1.1 每个请求都当作一个流，那么多个请求变成多个流，请求响应数据分成多个帧，不同流中的帧交错地发送给对方，这就是 HTTP/2 中的多路复用。

流的概念实现了单连接上多请求 - 响应并行，解决了线头阻塞的问题，减少了 TCP 连接数量和 TCP 连接慢启动造成的问题 所以 **http2 对于同一域名只需要创建一个连接**，而不是像 http/1.1 那样创建 6~8 个连接。

#### 服务端推送 (Server Push)

浏览器发送一个请求，服务器主动向浏览器推送与这个请求相关的资源，这样浏览器就不用发起后续请求。 Server-Push 主要是针对资源内联做出的优化，相较于 http/1.1 资源内联的优势:

- 客户端可以缓存推送的资源
- 客户端可以拒收推送过来的资源
- 推送资源可以由不同页面共享
- 服务器可以按照优先级推送资源

#### Header 压缩 (HPACK)

使用 HPACK 算法来压缩首部内容

#### 应用层的重置连接

对于 HTTP/1 来说，是通过设置 tcp segment 里的 reset flag 来通知对端关闭连接的。这种方式会直接断开连接，下次再发请求就必须重新建立连接。HTTP/2 引入 RST_STREAM 类型的 frame，可以在不断开连接的前提下取消某个 request 的 stream，表现更好。

#### 请求优先级设置

HTTP/2 里的每个 stream 都可以设置依赖 (Dependency) 和权重，可以按依赖树分配优先级，解决了关键请求被阻塞的问题

#### 流量控制

每个 http2 流都拥有自己的公示的流量窗口，它可以限制另一端发送数据。对于每个流来说，两端都必须告诉对方自己还有足够的空间来处理新的数据，而在该窗口被扩大前，另一端只被允许发送这么多数据。

#### HTTP/1 的几种优化可以弃用

合并文件、内联资源、雪碧图、域名分片对于 HTTP/2 来说是不必要的，使用 http2 尽可能将资源细粒化，文件分解地尽可能散，不用担心请求数多



---

## 11. 说说对 HTTP3 的了解

由于TCP和UDP两者在运输层存在一定差异，TCP的传递效率与UDP相比有天然劣势，于是Google基于UDP开发出了新的协议**QUIC(Quick UDP Internet Connections)**，希望取代TCP提高传输效率，后经过协商将QUIC协议更名为HTTP/3。

TCP、UDP是我们所熟悉的传输层协议，UDP比TCP相比效率更高但并不具备传输可靠性。而QUIC便是看中UDP传输效率这一特性，并结合了TCP、TLS、HTTP/2的优势，加以优化。

于是在QUIC上层的应用层所运行的HTTP协议也就被称为HTTP/3。

![img](E:\pogject\学习笔记\image\http\http3)

HTTP/3新特性

(1) **零RTT建立连接**，

传统HTTP/2(所有HTTP/2的浏览器均基于HTTPS)传输数据前需要三次RTT，即使将第一次TLS握手的对称秘钥缓存也需要两次RTT才能传递数据。

对于HTTP/3而言，仅仅需要一次RTT即可传递数据，如果将其缓存，就可将RTT减少至零。

其核心就是DH秘钥交换算法。

- 客户端向服务端请求数据。
- 服务端生成g、p、a三个随机数，用三个随机数生成A。将a保留后，将g、p、A(Server Config)传递到客户端。
- 客户端生成随机数b，将b保留后，用g、p、b三个随机数生成B。
- 客户端再使用A、b、p生成秘钥K，用K**加密HTTP数据**并与B一同发送到服务端。
- 服务端再使用B、a、p得到相同秘钥K，并解密HTTP数据。

(2) **连接迁移**

传统连接通过源IP、源端口、目的IP、目的端口进行连接，当网络发生更换后连接再次建立时延较长。

HTTP/3使用Connection ID对连接保持，只要Connection ID不改变，连接仍可维持。

(3) **队头阻塞/多路复用**

- TCP作为面向连接的协议，对每次请求序等到ACK才可继续连接，一旦中间连接丢失将会产生队头阻塞。
- HTTP/1.1中提出Pipelining的方式，单个TCP连接可多次发送请求，但依旧会有中间请求丢失产生阻塞的问题。
- HTTP/2中将请求粒度减小，通过Frame的方式进行请求的发送。但在TCP层Frame组合得到Stream进行传输，一旦出现Stream中的Frame丢失，其后方的Stream都将会被阻塞。
- 对于HTTP/2而言，浏览器会默认采取TLS方式传输，TLS基于Record组织数据，每个Record包含16K，其中有12个TCP的包，一旦其中一个TCP包出现问题将会导致整个Record无法解密。这也是网络环境较差时HTTP/2的传输速度比HTTP/1.1更慢的原因。
- HTTP/3基于UDP的传输，不保证连接可靠性，也就没有对头阻塞的后果。同样传输单元与加密单元为Packet，在TLS下也可避免对头阻塞的问题。

(4) **拥塞控制**

- 热拔插：TCP对于拥塞控制在于传输层，QUIC可在应用层操作改变拥塞控制方法。
- 前向纠错(FEC)：将数据切割成包后可对每个包进行异或运算，将运算结果随数据发送。一旦丢失数据可据此推算。(带宽换时间)
- 单调递增的Packet Number：TCP在超时重传后的两次ACK接受情况并不支持的很好。导致RTT和RTO的计算有所偏差。HTTP/3对此进行改进，一旦重传后的Packet N会递增。
- ACK Delay: HTTP/3在计算RTT时健壮的考虑了服务端的ACK处理时延。
- 更多地ACK块: 一般每次请求都会对应一个ACK，但这样也会浪费(下载场景只需返回数据即可)。于是可设计成每次返回3个ACK block。在HTTP/3将其扩充成最多可携带256 个ACK block。

(5) **流量控制**

TCP使用滑动窗口的方式对发送方的流量进行控制。而对接收方并无限制。在QUIC中便补齐了这一短板。

QUIC中接收方从单挑Stream和整条连接两个角度动态调整接受的窗口大小。



---

## 12. http请求方法

http请求方式有以下8种，其中get和post是最常用的：

1、OPTIONS

**向服务器查询支持的请求方法。**返回服务器针对特定资源所支持的HTTP请求方法，也可以利用向web服务器发送‘*’的请求来测试服务器的功能性

2、HEAD

向服务器索与GET请求相一致的响应，**只不过响应体将不会被返回，只返回报文首部**。这一方法可以再不必传输整个响应内容的情况下，就可以获取包含在响应小消息头中的元信息。

3、GET  

**用于获取资源。向特定的资源发出请求。**注意：GET方法不应当被用于产生“副作用”的操作中，例如在Web Application中，其中一个原因是GET可能会被网络蜘蛛等随意访问。Loadrunner中对应get请求函数：web_link和web_url

4、POST  

**用于发送实体主体。****向指定资源提交数据进行处理请求**（例如提交表单或者上传文件）。数据被包含在请求体中。POST请求可能会导致新的资源的建立和/或已有资源的修改。 Loadrunner中对应POST请求函数：web_submit_data,web_submit_form

5、PUT  

**用于上传文件**。向指定资源位置上传其最新内容

6、DELETE  

**用于删除文件**。请求服务器删除Request-URL所标识的资源

7、TRACE

**回显服务器收到的请求，主要用于测试或诊断**。服务器会将通信路径返回给客户端，方便查询某个中间服务器的状态，设计 Max-Forwards 头部字段，每次经过一个服务器，数值减一

8、CONNECT

**HTTP/1.1协议中预留给能够将连接改为管道方式的代理服务器**。要求使用隧道协议连接代理服务器，主要是用 SSL、TLS 协议将通信内容加密后经过网络隧道传输。

9、PATCH

在 HTTP 协议中，请求方法 **PATCH** 用于**对资源进行部分修改**。

---

###  options请求方法及使用场景

OPTIONS是除了GET和POST之外的其中一种 HTTP请求方法。

OPTIONS方法是用于请求获得由`Request-URI`标识的资源在请求/响应的通信过程中可以使用的功能选项。通过这个方法，客户端可以**在采取具体资源请求之前，决定对该资源采取何种必要措施，或者了解服务器的性能**。该请求方法的响应不能缓存。

OPTIONS请求方法的**主要用途**有两个：

- **获取服务器支持的所有HTTP请求方法**；
- **用来检查访问权限**。例如：JS 的 XMLHttpRequest对象进行 CORS 跨域资源共享时，对于复杂请求，就是使用 OPTIONS 方法发送嗅探请求，以判断是否有对指定资源的访问权限。





---

## 13. HTTPS如何保证安全

**HTTPS**（全称：Hypertext Transfer Protocol over Secure Socket Layer），是以安全为目标的HTTP通道，简单讲是HTTP的安全版。

HTTPS = HTTP + SSL/TLS，如今 SSL 已废弃，**所以现在只关注 HTTP + TLS**。为了解决 HTTP 协议的问题，HTTPS 引入了**数据加密**和**身份验证机制**。在开始传输数据之前，通过安全可靠的 TLS 协议进行加密，从而保证后续加密传输数据的安全性。

**TLS 协议**：**传输层安全性协议**（Transport Layer Security，**TLS**）及其前身**安全套接层**（Secure Sockets Layer，**SSL**）是一种安全协议，目的是为了保证**网络通信安全**和**数据完整性**。

**受 TLS 协议保护的通信过程**：先对传输的数据进行了加密（使用**对称加密算法**）。并且对称加密的密钥是为每一个连接唯一生成的（基于 TLS 握手阶段协商的加密算法和共享密钥），然后发送的每条消息都会通过消息验证码（Message authentication code, MAC），来进行消息完整性检查，最后还可以使用公钥对通信双方进行身份验证

**Https的作用**

- **内容加密** 建立一个信息安全通道，来保证数据传输的安全；
- **身份认证** 确认网站的真实性
- **数据完整性** 防止内容被第三方冒充或者篡改





---

## 14. 请问对称加密与非对称加密有什么区别？

**对称密钥加密**是指加密和解密使用同一个密钥的方式，这种方式存在的**最大问题就是密钥发送问题**，即如何安全地将密钥发给对方；

而**非对称加密**是指使用一对非对称密钥，即公钥和私钥，**公钥**可以随意发布，但**私钥**只有自己知道。发送密文的一方使用对方的公钥进行加密处理，对方接收到加密信息后，使用自己的私钥进行解密。

由于非对称加密的方式不需要发送用来解密的私钥，所以可以保证安全性；但是和对称加密比起来，**它非常的慢**，所以我们还是要用对称加密来传送消息，但**对称加密所使用的密钥**我们**可以通过非对称加密的方式发送出去**。



---

## 15. 非对称加密和对称加密，具体怎么实现的

**对称加密：**在对称加密算法中，加密使用的密钥和解密使用的密钥是相同的。也就是说，**加密和解密都是使用的同一个密钥**。

**非对称加密：**指加密和解密使用不同密钥的加密算法。非对称加密算法需要两个密钥：**公钥**（publickey）**私钥**（privatekey）。

公钥与私钥是一对存在，如果用公钥对数据进行加密，只有用对应的私钥才能解密；如果用私钥对数据进行加密，那么只有用对应的公钥才能解密。因为加密和解密使用的是两个不同的密钥，所以这种算法叫作**非对称加密算法**。

**解析：**

**1、对称加密算法的缺点**

- **要求提供一条安全的渠道使通讯双方在首次通讯时协商一个共同的密钥**。直接的面对面协商可能是不现实而且难于实施的，所以双方可能需要借助于邮件和电话等其它相对不够安全的手段来进行协商；
- **密钥的数目难于管理**。因为对于每一个合作者都需要使用不同的密钥，很难适应开放社会中大量的信息交流；
- 对称加密算法**一般不能提供信息完整性的鉴别**。它无法验证发送者和接受者的身份；
- **对称密钥的管理和分发工作是一件具有潜在危险的和烦琐的过程**。对称加密是基于共同保守秘密来实现的，采用对称加密技术的贸易双方必须保证采用的是相同的密钥，保证彼此密钥的交换是安全可靠的，同时还要设定防止密钥泄密和更改密钥的程序。

**2、两种加密体制的特点**

非对称密码体制的特点：算法强度复杂、安全性依赖于算法与密钥但是由于其算法复杂，而使得加密解密速度没有对称加密解密的速度快。

对称密码体制中只有一种密钥，并且是非公开的，如果要解密就得让对方知道密钥，所以保证其安全性就是保证密钥的安全。而非对称密钥体制有两种密钥，其中一个是公开的，这样就可以不需要像对称密码那样传输对方的密钥了。这样安全性就大了很多。

假设两个用户要加密交换数据，**双方交换公钥，使用时一方用对方的公钥加密**，另一方即**可用自己的私钥解密。**

如果企业中有n个用户，企业需要生成n对密钥，并分发n个公钥。由于公钥是可以公开的，用户只要保管好自己的私钥即可，因此加密密钥的分发将变得 十分简单。同时，由于每个用户的私钥是唯一的，其他用户除了可以通过"信息发送者的公钥"来验证信息的来源是否真实，还可以确保发送者无法否认曾发送过该信息。非对称加密的**缺点**是**加解密速度要远远慢于对称加密**，在某些极端情况下，甚至能比对称加密慢上1000倍。

> 非对称的好处显而易见，非对称加密体系不要求通信双方事先传递密钥或有任何约定就能完成保密通信，并且密钥管理方便，可实现防止假冒和抵赖，因此，更适合网络通信中的保密通信要求。

**3、什么是数字证书**

- **数字证书**就是**互联网通讯中标志通讯各方身份信息的一串数字**，提供了一种在Internet上验证通信实体身份的方式，数字证书不是数字身份证，而是**身份认证机构盖在数字身份证上的一个章或印**（或者说加在数字身份证上的一个签名）。
- 它是由权威机构——CA机构，又称为**证书授权**（Certificate Authority）中心发行的，人们可以在网上用它来识别对方的身份。
- **数字证书绑定了公钥及其持有者的真实身份**，它类似于现实生活中的居民身份证，所不同的是数字证书不再是纸质的证照，而是一段含有证书持有者身份信息并经过认证中心审核签发的电子数据，广泛用在电子商务和移动互联网中。

**4、什么是数字签名**

4.1 数字签名是将摘要信息用发送者的私钥加密，与原文一起传送给接收者。接收者只有用发送者的公钥才能解密被加密的摘要信息，然后用HASH函数对收到的原文产生一个摘要信息，与解密的摘要信息对比。

> 如果相同，则说明收到的信息是完整的，在传输过程中没有被修改；
> 否则说明信息被修改过，因此**数字签名能够验证信息的完整性。**
> 如果中途数据被纂改或者丢失。那么对方就可以根据数字签名来辨别是否是来自对方的第一手信息数据。

4.2 数字签名是个**加密**的过程，数字签名验证是个**解密**的过程。

4.3 数字签名用来，保证信息传输的完整性、发送者的身份认证、防止交易中的抵赖发生。

非对称加密算法实现机密信息交换的**基本过程**是：

1. 甲方生成一对密钥并将其中的一把作为公用密钥向其它方公开；
2. 得到该公用密钥的乙方使用该密钥对机密信息进行加密后再发送给甲方；
3. 甲方再用自己保存的另一把专用密钥对加密后的信息进行解密。

**5、非对称加密和对称加密在HTTPS协议中的应用**

- 5.1 浏览器向服务器发出请求，询问对方支持的对称加密算法和非对称加密算法；服务器回应自己支持的算法。

- 5.2 浏览器选择双方都支持的加密算法，并请求服务器出示自己的证书；服务器回应自己的证书。

- 5.3 浏览器随机产生一个用于本次会话的对称加密的钥匙，并使用服务器证书中附带的公钥对该钥匙进行加密后传递给服务器；服务器为本次会话保持该对称加密的钥匙。第三方不知道服务器的私钥，即使截获了数据也无法解密。非对称加密让任何浏览器都可以与服务器进行加密会话。
- 5.4 浏览器使用对称加密的钥匙对请求消息加密后传送给服务器，服务器使用该对称加密的钥匙进行解密；服务器使用对称加密的钥匙对响应消息加密后传送给浏览器，浏览器使用该对称加密的钥匙进行解密。第三方不知道对称加密的钥匙，即使截获了数据也无法解密。对称加密提高了加密速度 。

**6、完整的非对称加密过程**

假如现在 你向支付宝 转账（术语数据信息），为了保证信息传送的保密性、真实性、完整性和不可否认性，需要对传送的信息进行数字加密和签名，其传送过程为：

1. 首先你要确认是否是支付宝的数字证书，如果确认为支付宝身份后，则对方真实可信。可以向对方传送信息
2. 你准备好要传送的数字信息（明文）计算要转的多少钱，对方支付宝账号等；
3. 你对数字信息进行哈希运算，得到一个信息摘要（客户端主要职责）；
4. 你用自己的私钥对信息摘要进行加密得到 你 的数字签名，并将其附在数字信息上；
5. 你随机产生一个加密密钥，并用此密码对要发送的信息进行加密（密文）；
6. 你用支付宝的公钥对刚才随机产生的加密密钥进行加密，将加密后的 DES 密钥连同密文一起传送给支付宝
7. 支付宝收到 你 传送来的密文和加密过的 DES 密钥，先用自己的私钥对加密的 DES 密钥进行解密，得到 你随机产生的加密密钥；
8. 支付宝 然后用随机密钥对收到的密文进行解密，得到明文的数字信息，然后将随机密钥抛弃；
9. 支付宝 用你 的公钥对 你的的数字签名进行解密，得到信息摘要；
10. 支付宝用相同的哈希算法对收到的明文再进行一次哈希运算，得到一个新的信息摘要；
11. 支付宝将收到的信息摘要和新产生的信息摘要进行比较，如果一致，说明收到的信息没有被修改过；
12. 确定收到信息，然后进行向对方进行付款交易，一次非对称密过程结束。



---

## 16. https加密解密流程

https加密解密流程分成以下8个步骤：

1. **客户端发起HTTPS请求** 这个没什么好说的，就是用户在浏览器里输入一个HTTPS网址，然后连接到服务端的**443端口**。
2. **服务端的配置** 采用HTTPS协议的服务器必须要有一套**数字证书**，可以自己制作，也可以向组织申请。区别就是自己颁发的证书需要客户端验证通过，才可以继续访问，而使用受信任的公司申请的证书则不会弹出提示页面。**这套证书其实就是一对公钥和私钥**。如果对公钥不太理解，可以想象成一把钥匙和一个锁头，只是世界上只有你一个人有这把钥匙，你可以把锁头给别人，别人可以用这个锁把重要的东西锁起来，然后发给你，因为只有你一个人有这把钥匙，所以只有你才能看到被这把锁锁起来的东西。
3. **传送证书** 这个证书其实就是**公钥**，只是包含了很多信息，如证书的颁发机构，过期时间等等。
4. **客户端解析证书** 这部分工作是由客户端的SSL/TLS来完成的，首先会验证公钥是否有效，比如颁发机构，过期时间等等，如果发现异常，则会弹出一个警示框，提示证书存在的问题。如果证书没有问题，那么就生成一个**随机值**。然后用证书（也就是公钥）对这个随机值进行加密。就好像上面说的，把随机值用锁头锁起来，这样除非有钥匙，不然看不到被锁住的内容。
5. **传送加密信息** 这部分传送的是用证书加密后的随机值，目的是让服务端得到这个随机值，以后客户端和服务端的通信就可以通过这个随机值来进行加密解密了。
6. **服务端解密信息** 服务端用私钥解密后，得到了客户端传过来的随机值，然后把内容通过该随机值进行对称加密，将信息和私钥通过某种算法混合在一起，这样除非知道私钥，不然无法获取内容，而正好客户端和服务端都知道这个私钥，所以只要加密算法够彪悍，私钥够复杂，数据就够安全。
7. **传输加密后的信息** 这部分信息就是服务端用私钥加密后的信息，可以在客户端用随机值解密还原。
8. **客户端解密信息** 客户端用之前生产的私钥解密服务端传过来的信息，于是获取了解密后的内容。整个过程第三方即使监听到了数据，也束手无策。



---

## 17. 请问HTTP的请求和响应由哪几个部分组成？

HTTP**请求信息**由3部分组成：

- 请求方法（GET/POST）、URI、协议/版本

- 请求头(Request Header)：Content-Type、端口号Host、Cookie
- 请求正文：包含客户提交的查询字符串信息，请求头和请求正文之间是一个空行

**HTTP响应**也由3个部分构成：

- 状态行：状态代码及描述 如404、500等
- 响应头(Response Header)：Content-Type 、Server、Date
- 响应正文：html代码





----

## 18. 请问IP地址分为哪几类？

IP地址是指互联网协议地址，是IP协议提供的一种统一的地址格式，它为互联网上的每一个网络和每一台主机分配一个逻辑地址，以此来屏蔽物理地址的差异。IP地址编址方案将IP地址空间划分为A、B、C、D、E五类，其中**A、B、C是基本类**，D、E类作为多播和保留使用，为特殊地址。

每个IP地址包括两个标识码（ID），即**网络ID和主机ID**。同一个物理网络上的所有主机都使用同一个网络ID，网络上的一个主机（包括网络上工作站，服务器和路由器等）有一个主机ID与其对应。A~E类地址的特点如下：

**A类地址：**以0开头，第一个字节范围：0~127；

**B类地址：**以10开头，第一个字节范围：128~191；

**C类地址：**以110开头，第一个字节范围：192~223；

**D类地址：**以1110开头，第一个字节范围为224~239；

**E类地址：**以1111开头，保留地址

**（1）、A类地址：1字节的网络地址 + 3字节主机地址，网络地址的最高位必须是“0”**

一个A类IP地址是指， 在IP地址的四段号码中，第一段号码为网络号码，剩下的三段号码为本地计算机的号码。如果用二进制表示IP地址的话，A类IP地址就由1字节的网络地址和3字节主机地址组成，网络地址的最高位必须是“0”。A类IP地址中网络的标识长度为8位，主机标识的长度为24位，A类网络地址数量较少，有126个网络，每个网络可以容纳主机数达1600多万台。

A类IP地址的地址范围1.0.0.0到127.255.255.255（二进制表示为：00000001 00000000 00000000 00000000 - 01111110 11111111 11111111 11111111），最后一个是广播地址。A类IP地址的子网掩码为255.0.0.0，每个网络支持的最大主机数为256的3次方-2=16777214台。

**（2）、B类地址: 2字节的网络地址 + 2字节主机地址，网络地址的最高位必须是“10”**

一个B类IP地址是指，在IP地址的四段号码中，前两段号码为网络号码。如果用二进制表示IP地址的话，B类IP地址就由2字节的网络地址和2字节主机地址组成，网络地址的最高位必须是“10”。B类IP地址中网络的标识长度为16位，主机标识的长度为16位，B类网络地址适用于中等规模的网络，有16384个网络，每个网络所能容纳的计算机数为6万多台。

B类IP地址地址范围128.0.0.0-191.255.255.255（二进制表示为：10000000 00000000 00000000 00000000—-10111111 11111111 11111111 11111111），最后一个是广播地址。B类IP地址的子网掩码为255.255.0.0，每个网络支持的最大主机数为256的2次方-2=65534台。

**（3）、C类地址: 3字节的网络地址 + 1字节主机地址，网络地址的最高位必须是“110”**

一个C类IP地址是指，在IP地址的四段号码中，前三段号码为网络号码，剩下的一段号码为本地计算机的号码。如果用二进制表示IP地址的话，C类IP地址就由3字节的网络地址和1字节主机地址组成，网络地址的最高位必须是“110”。C类IP地址中网络的标识长度为24位，主机标识的长度为8位，C类网络地址数量较多，有209万余个网络。适用于小规模的局域网络，每个网络最多只能包含254台计算机。

C类IP地址范围192.0.0.0-223.255.255.255（二进制表示为: 11000000 00000000 00000000 00000000 - 11011111 11111111 11111111 11111111）。C类IP地址的子网掩码为255.255.255.0，每个网络支持的最大主机数为256-2=254台。

**（4）、D类地址:多播地址，用于1对多通信，最高位必须是“1110”**

D类IP地址在历史上被叫做多播地址(multicast address)，即组播地址。在以太网中，多播地址命名了一组应该在这个网络中应用接收到一个分组的站点。多播地址的最高位必须是“1110”，范围从224.0.0.0到239.255.255.255。

**（5）、E类地址:为保留地址，最高位必须是“1111”**



----

## 19. 请简介地址解析协议ARP的工作原理。

ARP是**地址解析协议**，其工作原理为：

（1）首先，每个主机都会在自己的ARP缓冲区中建立一个ARP列表，以表示IP地址和MAC地址之间的对应关系；

（2）当源主机要发送数据时，**首先检查ARP列表中是否有对应IP地址的目的主机的MAC地址**，如果有，则直接发送数据，如果没有，就向本网段的所有主机发送ARP数据包，该数据包包括的内容有：源主机IP地址，源主机MAC地址，目的主机的IP地址；

（3）**当本网络的所有主机收到该ARP数据包时，首先检查数据包中的IP地址是否是自己的IP地址**，如果不是，则忽略该数据包，如果是，则首先从数据包中取出源主机的IP和MAC地址写入到ARP列表中，如果已经存在，则覆盖，然后将自己的MAC地址写入ARP响应包中，告诉源主机自己是它想要找的MAC地址；

（4）源主机收到ARP响应包后。将目的主机的IP和MAC地址写入ARP列表，并利用此信息发送数据。如果源主机一直没有收到ARP响应数据包，表示ARP查询失败。



---

## 20.有什么方法可以保持前后端实时通信

实现保持前后端实时通信的方式有以下几种

- WebSocket： IE10以上才支持，Chrome16, FireFox11,Safari7以及Opera12以上完全支持，移动端形势大
- event-source: IE完全不支持（注意是任何版本都不支持），Edge76，Chrome6,Firefox6,Safari5和Opera以上支持， 移动端形势大好
- AJAX轮询： 用于兼容低版本的浏览器
- 永久帧（ forever iframe）可用于兼容低版本的浏览器
- flash socket 可用于兼容低版本的浏览器

**这几种方式的优缺点**

**1.WebSocket**

- 优点：WebSocket 是 HTML5 开始提供的一种在单个 TCP 连接上进行全双工通讯的协议，可从HTTP升级而来，浏览器和服务器只需要一次握手，就可以进行持续的，双向的数据传输，因此能显著节约资源和带宽
- 缺点：1. 兼容性问题:不支持较低版本的IE浏览器（IE9及以下）2.不支持断线重连，需要手写心跳连接的逻辑 3.通信机制相对复杂

**2. server-sent-event（event-source）**

- 优点：（1）只需一次请求，便可以stream的方式多次传送数据，节约资源和带宽 （2）相对WebSocket来说简单易用 （3）内置断线重连功能(retry)
- 缺点： （1）是单向的，只支持服务端->客户端的数据传送，客户端到服务端的通信仍然依靠AJAX，没有”一家人整整齐齐“的感觉（2）兼容性令人担忧，IE浏览器完全不支持

**3. AJAX轮询**

- 优点：兼容性良好，对标低版本IE
- 缺点：请求中有大半是无用的请求，浪费资源

**4.Flash Socket**

- 缺点：（1）浏览器开启时flash需要用户确认，（2）加载时间长，用户体验较差 （3）大多数移动端浏览器不支持flash，为重灾区
- 优点： 兼容低版本浏览器

**5. 永久帧（ forever iframe）**

- 缺点： iframe会产生进度条一直存在的问题，用户体验差
- 优点：兼容低版本IE浏览器

**综上，综合兼容性和用户体验的问题，我在项目中选用了WebSocket ->server-sent-event -> AJAX轮询这三种方式做从上到下的兼容**



---

## 21. 常见http status

**1XX系列**：指定客户端应相应的某些动作，**代表请求已被接受，需要继续处理**。由于 HTTP/1.0 协议中没有定义任何 1xx 状态码，所以除非在某些试验条件下，服务器禁止向此类客户端发送 1xx 响应。

**2XX系列**：代表**请求已成功被服务器接收、理解、并接受**。这系列中最常见的有200、201状态码。

**3XX系列**：代表**需要客户端采取进一步的操作才能完成请求**，这些状态码用来重定向，后续的请求地址（重定向目标）在本次响应的 Location 域中指明。这系列中最常见的有301、302、304状态码。

**4XX系列**：表示**请求错误**。代表了客户端看起来可能发生了错误，妨碍了服务器的处理。常见有：401、404状态码。

**5xx系列**：代表了**服务器在处理请求的过程中有错误或者异常状态发生**，也有可能是服务器意识到以当前的软硬件资源无法完成对请求的处理。常见有500、503状态码。

**2开头 （请求成功）表示成功处理了请求的状态代码。**

- **200** （成功） 服务器已成功处理了请求。 通常，这表示服务器提供了请求的网页。
- **201** （已创建） 请求成功并且服务器创建了新的资源。
- 202 （已接受） 服务器已接受请求，但尚未处理。
- 203 （非授权信息） 服务器已成功处理了请求，但返回的信息可能来自另一来源。
- 204 （无内容） 服务器成功处理了请求，但没有返回任何内容。
- 205 （重置内容） 服务器成功处理了请求，但没有返回任何内容。
- 206 （部分内容） 服务器成功处理了部分 GET 请求。

**3开头 （请求被重定向）表示要完成请求，需要进一步操作。 通常，这些状态代码用来重定向。**

- **300** （多种选择） 针对请求，服务器可执行多种操作。 服务器可根据请求者 (user agent) 选择一项操作，或提供操作列表供请求者选择。
- **301** （永久移动） 请求的网页已永久移动到新位置。 服务器返回此响应（对 GET 或 HEAD 请求的响应）时，会自动将请求者转到新位置。
- **302** （临时移动） 服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求。
- 303 （查看其他位置） 请求者应当对不同的位置使用单独的 GET 请求来检索响应时，服务器返回此代码。
- **304** （未修改） 自从上次请求后，请求的网页未修改过。 服务器返回此响应时，不会返回网页内容。
- 305 （使用代理） 请求者只能使用代理访问请求的网页。 如果服务器返回此响应，还表示请求者应使用代理。
- **307** （临时重定向） 服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以后的请求。

**4开头 （请求错误）这些状态代码表示请求可能出错，妨碍了服务器的处理。**

- **400** （错误请求） 服务器不理解请求的语法。
- **401** （未授权） 请求要求身份验证。 对于需要登录的网页，服务器可能返回此响应。
- **403** （禁止） 服务器拒绝请求。
- **404** （未找到） 服务器找不到请求的网页。
- 405 （方法禁用） 禁用请求中指定的方法。
- 406 （不接受） 无法使用请求的内容特性响应请求的网页。
- 407 （需要代理授权） 此状态代码与 401（未授权）类似，但指定请求者应当授权使用代理。
- **408** （请求超时） 服务器等候请求时发生超时。
- 409 （冲突） 服务器在完成请求时发生冲突。 服务器必须在响应中包含有关冲突的信息。
- 410 （已删除） 如果请求的资源已永久删除，服务器就会返回此响应。
- 411 （需要有效长度） 服务器不接受不含有效内容长度标头字段的请求。
- 412 （未满足前提条件） 服务器未满足请求者在请求中设置的其中一个前提条件。
- 413 （请求实体过大） 服务器无法处理请求，因为请求实体过大，超出服务器的处理能力。
- 414 （请求的 URI 过长） 请求的 URI（通常为网址）过长，服务器无法处理。
- 415 （不支持的媒体类型） 请求的格式不受请求页面的支持。
- 416 （请求范围不符合要求） 如果页面无法提供请求的范围，则服务器会返回此状态代码。
- 417 （未满足期望值） 服务器未满足"期望"请求标头字段的要求。

**5开头（服务器错误）这些状态代码表示服务器在尝试处理请求时发生内部错误。 这些错误可能是服务器本身的错误，而不是请求出错。**

- **500** （服务器内部错误） 服务器遇到错误，无法完成请求。
- 501 （尚未实施） 服务器不具备完成请求的功能。 例如，服务器无法识别请求方法时可能会返回此代码。
- **502** （错误网关） 服务器作为网关或代理，从上游服务器收到无效响应。
- **503** （服务不可用） 服务器目前无法使用（由于超载或停机维护）。 通常，这只是暂时状态。
- 504 （网关超时） 服务器作为网关或代理，但是没有及时从上游服务器收到请求。
- 505 （HTTP 版本不受支持） 服务器不支持请求中所用的 HTTP 协议版本。

---

## 22. 具体讲解一下http 的option  请求方式

除了post和get还有6种请求方式分别是：OPTIONS、HEAD、PUT、DELETE、TRACE、CONNECT、patch

**HTTP 的OPTIONS 方法** 用于获取目的资源所支持的通信选项。客户端可以对特定的 URL 使用 OPTIONS 方法，也可以对整站（通过将 URL 设置为“*”）使用该方法

**作用**：

1. 检测服务器所支持的请求方法

   可以使用 OPTIONS 方法对服务器发起请求，以检测服务器支持哪些 HTTP 方法：

   ```bash
   curl -X OPTIONS http://example.org -i
   ```

   ```bash
   $ curl -X OPTIONS https://www.ncbi.nlm.nih.gov/ -i
     % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                    Dload  Upload   Total   Spent    Left  Speed
     0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0HTTP/2 200
   strict-transport-security: max-age=31536000; includeSubDomains; preload
   referrer-policy: origin-when-cross-origin
   content-security-policy: upgrade-insecure-requests
   caf: 2.0.1
   allow: OPTIONS,HEAD,GET,POST
   x-ua-compatible: IE=Edge
   x-xss-protection: 1; mode=block
   content-length: 0
   content-type: text/html
   date: Tue, 05 Jul 2022 02:52:42 GMT
   server: Apache
   
   
   ```

   

2. CORS 中的预检请求

   在 **CORS** 中，可以使用 OPTIONS 方法发起一个预检请求，以检测实际请求是否可以被服务器所接受。预检请求报文中的 [Access-Control-Request-Method](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Access-Control-Request-Method) 首部字段告知服务器实际请求所使用的 HTTP 方法；[Access-Control-Request-Headers](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Access-Control-Request-Headers) 首部字段告知服务器实际请求所携带的自定义首部字段。服务器基于从预检请求获得的信息来判断，是否接受接下来的实际请求。



---

## 23. FTP DNS 基于什么协议

DNS (Domain Name Service 域名服务) 协议基于 UDP协议

FTP (File Transfer Protocol 文件传输协议) 基于 TCP协议

DNS和FTP都是应用层协议



---

## 24. URL 路径包含什么, URI 是什么

**URL 路径包含什么**

一个完整的url分为4部分：

1. 协议 例 Http（超文本传输协议） 、Https
2. 域名 例`www.baidu.com`为网站名字。 `baidu.com`为一级域名，`www`是服务
3. 端口 不填写的话默认走的是80端口号
4. 路径 `http://www.baidu.com/路径1/路径2`。/表示根目录
5. 查询参数 `http://www.baidu.com/路径1/路径1.2?name="man"`(可有可无)

**URI 是什么**

**URI**是**一个用于标识互联网资源名称的字符串**。 该种标识允许用户对网络中（一般指[万维网](https://link.jianshu.com/?t=https://zh.wikipedia.org/wiki/万维网)）的资源通过特定的协议进行交互操作。URI的最常见的形式是**统一资源定位符**（URL），经常指定为非正式的网址。更罕见的用法是**统一资源名称**（URN），其目的是通过提供一种途径。用于在特定的命名空间资源的标识，以补充网址。

**URI**（**统一资源标识符**）是一个指向资源的字符串。最通常用在 [URL](https://developer.mozilla.org/zh-CN/docs/Glossary/URL) 上来指定Web上资源文件的具体位置。相比之下，[URN](https://developer.mozilla.org/zh-CN/docs/Glossary/URN) 是在给定的命名空间用名字指向具体的资源，如：书本的ISBN。

**扩展**：

URL和URN是URI的子集，URI属于URL更高层次的抽象，一种字符串文本标准。



---

## 25. 301和302的含义

301和302都是重定向的状态码，重定向（Redirect）是指通过各种方法将客户端的网络请求重新定义或指定一个新方向转到其他位置（重定向包括**网页重定向**、**域名重定向**）。

301 redirect: 301 代表**永久性转移**(Permanently Moved)

302 redirect: 302 代表**暂时性转移**(Temporarily Moved )

**相同点：**都表示重定向，就是说浏览器在拿到服务器返回的这个状态码后会自动跳转到一个新的URL地址，这个地址可以从响应的Location首部中获取（用户看到的效果就是他输入的地址A瞬间变成了另一个地址B）

**不同点：**

1. 301表示旧地址A的资源已经被永久地移除了（这个资源不可访问了），搜索引擎在抓取新内容的同时也将旧的网址交换为重定向之后的网址；

   302表示旧地址A的资源还在（仍然可以访问），这个重定向只是临时地从旧地址A跳转到地址B，搜索引擎会抓取新的内容而保存旧的网址。

2. 302会出现“网址劫持”现象，从A网址302重定向到B网址，由于部分搜索引擎无法总是抓取到目标网址，或者B网址对用户展示不够友好，因此浏览器会仍旧显示A网址，但是所用的网页内容却是B网址上的内容。

**应用场景**

301：域名需要切换、协议从http变成https；

302：未登录时访问已登录页时跳转到登录页面、404后跳转首页



---

## 26. DNS是什么

DNS（Domain Name Server，域名服务器）是**进行域名(domain name)和与之相对应的IP地址 (IP address)转换的服务器。**

### DNS

DNS中保存了一张域名(domain name)和与之相对应的IP地址 (IP address)的表，以解析消息的域名。 域名是Internet上某一台计算机或计算机组的名称，用于在数据传输时标识计算机的电子方位（有时也指地理位置）。

DNS是应用层协议，事实上他是为其他应用层协议工作的，包括不限于HTTP和SMTP以及FTP，用于将用户提供的主机名解析为ip地址。

域名是由一串用点分隔的名字组成的，通常包含组织名，而且始终包括两到三个字母的后缀，以指明组织的类型或该域所在的国家或地区。

DNS（Domain Names System），域名系统，是互联网一项服务，是进行域名和与之相对应的 IP 地址进行转换的服务器

简单来讲，**`DNS`相当于一个翻译官，负责将域名翻译成`ip`地址**

- IP 地址：**一长串能够唯一地标记网络上的计算机的数字**
- 域名：是由一串用点分隔的名字组成的 Internet 上某一台计算机或计算机组的名称，用于在数据传输时对计算机的定位标识

![img](E:\pogject\学习笔记\image\http\DNS1)

### 域名

域名是一个具有层次的结构，从上到下一次为根域名、顶级域名、二级域名、三级域名...

![img](E:\pogject\学习笔记\image\http\DNS2)

例如`www.xxx.com`，`www`为三级域名、`xxx`为二级域名、`com`为顶级域名，系统为用户做了兼容，域名末尾的根域名`.`一般不需要输入

在域名的每一层都会有一个域名服务器，如下图：

![img](E:\pogject\学习笔记\image\http\DNS3)

除此之外，还有电脑默认的本地域名服务器



###  DNS同时使用TCP和UDP协议

**DNS占用53号端口，同时使用TCP和UDP协议。**

（1）**在区域传输的时候使用TCP协议**

- 辅域名服务器会定时（一般3小时）向主域名服务器进行查询以便了解数据是否有变动。如有变动，会执行一次区域传送，进行数据同步。区域传送使用TCP而不是UDP，因为数据同步传送的数据量比一个请求应答的数据量要多得多。
- TCP是一种可靠连接，保证了数据的准确性。

（2）**在域名解析的时候使用UDP协议**

- 客户端向DNS服务器查询域名，一般返回的内容都不超过512字节，用UDP传输即可。不用经过三次握手，这样DNS服务器负载更低，响应更快。理论上说，客户端也可以指定向DNS服务器查询时用TCP，但事实上，很多DNS服务器进行配置的时候，仅支持UDP查询包。



### 查询方式

DNS 查询的方式有两种：

#### 递归查询

- 递归查询：如果 A 请求 B，**那么 B 作为请求的接收者一定要给 A 想要的答案**
- **递归查询**指的是查询请求发出后，域名服务器代为向下一级域名服务器发出请求，最后向用户返回查询的最终结果。使用递归 查询，用户只需要发出一次查询请求。

![img](E:\pogject\学习笔记\image\http\DNS4)

#### 迭代查询

- 迭代查询：如果接收者 B 没有请求者 A 所需要的准确内容**，接收者 B 将告诉请求者 A，如何去获得这个内容，但是自己并不去发出请求**
- **迭代查询**指的是查询请求后，域名服务器返回单次查询的结果。下一级的查询由用户自己请求。使用迭代查询，用户需要发出 多次的查询请求

![img](E:\pogject\学习笔记\image\js\DNS5)

一般我们向本地 DNS 服务器发送请求的方式就是递归查询，因为我们只需要发出一次请求，然后本地 DNS 服务器返回给我 们最终的请求结果。而本地 DNS 服务器向其他域名服务器请求的过程是迭代查询的过程，因为每一次域名服务器只返回单次 查询的结果，下一级的查询由本地 DNS 服务器自己进行。



### 域名缓存

在域名服务器解析的时候，使用缓存保存域名和`IP`地址的映射

计算机中`DNS`的记录也分成了两种缓存方式：

- **浏览器缓存**：浏览器在获取网站域名的实际 IP 地址后会对其进行缓存，减少网络请求的损耗
- **操作系统缓存**：操作系统的缓存其实是用户自己配置的 `hosts` 文件

### 查询过程

解析域名的过程如下：

- 首先搜索**浏览器的 DNS 缓存**，缓存中维护一张域名与 IP 地址的对应表
- 若没有命中，则继续搜索**操作系统的 DNS 缓存**
- 若仍然没有命中，则**操作系统**将域名发送至**本地域名服务器**，本地域名服务器采用**递归查询**自己的 DNS 缓存，查找成功则返回结果
- 若**本地域名服务器**的 DNS 缓存没有命中，则**本地域名服务器**向**上级域名服务器**进行迭代查询
  - 首先**本地域名服务器**向**根域名服务器**发起请求，**根域名服务器**返回**顶级域名服务器的地址**给**本地服务器**
  - **本地域名服务器**拿到这个**顶级域名服务器的地址**后，就向**其**发起请求，获取**权限域名服务器的地址**
  - **本地域名服务器**根据权限域名服务器的地址向其发起请求，**最终得到该域名对应的 IP 地址**
- **本地域名服务器**将得到的 IP 地址返回给**操作系统**，同时自己将 IP 地址缓存起来
- **操作系统**将 IP 地址返回给**浏览器**，同时自己也将 IP 地址缓存起
- 至此，**浏览器**就得到了域名对应的 IP 地址，并将 IP 地址缓存起

流程如下图所示：

![img](https://static.vue-js.com/bec3c740-b78f-11eb-ab90-d9ae814b240d.png)

### DNS 记录和报文

DNS 服务器中以资源记录的形式存储信息，每一个 DNS 响应报文一般包含多条资源记录。一条资源记录的具体的格式为

```apl
（Name，Value，Type，TTL）
```

其中 TTL 是**资源记录的生存时间**，它定义了资源记录能够被其他的 DNS 服务器缓存多长时间。

常用的一共有四种 Type 的值，分别是 A、NS、CNAME 和 MX ，不同 Type 的值，对应资源记录代表的意义不同。

1. 如果 Type = A，则 Name 是**主机名**，Value 是**主机名对应的 IP 地址**。因此一条记录为 A 的资源记录，提供了标 准的主机名到 IP 地址的映射。
2. 如果 Type = NS，则 Name 是个**域名**，Value 是**负责该域名的 DNS 服务器的主机名**。这个记录主要用于 DNS 链式 查询时，返回下一级需要查询的 DNS 服务器的信息。
3. 如果 Type = CNAME，则 Name 为**别名**，Value 为**该主机的规范主机名**。该条记录用于向查询的主机返回一个主机名 对应的规范主机名，从而告诉查询主机去查询这个主机名的 IP 地址。**主机别名主要是为了通过给一些复杂的主机名提供 一个便于记忆的简单的别名。**
4. 如果 Type = MX，则 Name 为一个**邮件服务器的别名**，Value 为**邮件服务器的规范主机名**。它的作用和 CNAME 是一 样的，都是为了解决规范主机名不利于记忆的缺点。





---

## 27.http缓存有几种？

### 缓存策略

在阐述HTTP不同缓存策略之前，我们需要知道用户刷新/访问行为 的手段分成三类：

- 在URI输入栏中输入然后回车/通过书签访问
- F5/点击工具栏中的刷新按钮/右键菜单重新加载
- Ctl+F5 （**完全不使用HTTP缓存**）

不同的刷新手段，会导致浏览器使用不同的缓存策略，我们下面会分析到

HTTP 缓存主要是通过请求和响应报文头中的对应 Header 信息，来控制缓存的策略。
响应头中相关字段为Expires、Cache-Control、Last-Modified、Etag。

浏览器每次发起请求时，先在本地缓存中查找结果以及缓存标识，根据缓存标识来判断是否使用本地缓存。如果缓存有效，则使用本地缓存；否则，则向服务器发起请求并携带缓存标识。根据是否需向服务器发起HTTP请求，将缓存过程划分为两个部分：
强制缓存和协商缓存，强缓优先于协商缓存。

- 强缓存，服务器通知浏览器一个缓存时间，在缓存时间内，下次请求，直接用缓存，不在时间内，执行比较缓存策略。
- 协商缓存，让客户端与服务器之间能实现缓存文件是否更新的验证、提升缓存的复用率，将缓存信息中的Etag和Last-Modified
  通过请求发送给服务器，由服务器校验，返回304状态码时，浏览器直接使用缓存。

HTTP缓存都是从第二次请求开始的：

- 第一次请求资源时，服务器返回资源，并在response header中回传资源的缓存策略；

- 第二次请求时，浏览器判断这些请求参数，击中强缓存就直接200，否则就把请求参数加到request header头中传给服务器，看是否击中协商缓存，击中则返回304，否则服务器会返回新的资源。这是缓存运作的一个整体流程图：

  ![img](E:\pogject\学习笔记\image\http\HTTP缓存2)

### http缓存的分类

根据**是否需要重新向服务器发起请求来分类**，可分为(强制缓存，协商缓存) 

根据**是否可以被单个或者多个用户使用来分类**，可分为(私有缓存，共享缓存) 

强制缓存如果生效，不需要再和服务器发生交互，**而协商缓存不管是否生效，都需要与服务端发生交互**。下面是强制缓存和协商缓存的一些对比：

![img](E:\pogject\学习笔记\image\js\http缓存)



### 强制缓存

强制缓存**在缓存数据未失效的情况下**（即Cache-Control的max-age没有过期或者Expires的缓存时间没有过期），**那么就会直接使用浏览器的缓存数据**，不会再向服务器发送任何请求。强制缓存生效时，http状态码为200。**这种方式页面的加载速度是最快的，性能也是很好的，但是在这期间，如果服务器端的资源修改了，页面上是拿不到的，因为它不会再向服务器发请求了**。

这种情况就是我们在开发种经常遇到的，比如你修改了页面上的某个样式，在页面上刷新了但没有生效，因为走的是强缓存，**所以Ctrl + F5一顿操作之后就好了**。 跟强制缓存相关的header头属性有（Pragma/Cache-Control/Expires）， Pragma和Cache-control共存时，**Pragma的优先级是比Cache-Control高的。**

先看看浏览器请求资源的情况：

![浏览器第一次请求资源](E:\pogject\学习笔记\image\http\1073178728-5bed42a8401b1_articlex)

强制缓存：
在浏览器已经缓存数据的情况下，使用强制缓存去请求数据的流程是这样的：

![强制缓存](E:\pogject\学习笔记\image\http\1447835885-5adfe19706507_articlex)
从流程图可以看到，强制缓存，在缓存数据未失效的情况下，可以直接使用缓存数据，不需要再请求服务器，那么浏览器是如何判断缓存数据是否失效呢？

- 强缓存命中则直接读取浏览器本地的资源，在network中显示的是from memory或者from disk
- 控制强制缓存的字段有：Cache-Control（http1.1）和Expires（http1.0）
- **Cache-control是一个相对时间**，用以表达自上次请求正确的资源之后的多少秒的时间段内缓存有效。
- **Expires是一个绝对时间**。用以表达在这个时间点之前发起请求可以直接从浏览器中读取数据，而无需发起请求
- **Cache-Control的优先级比Expires的优先级高**。前者的出现是为了解决Expires在浏览器时间被手动更改导致缓存判断错误的问题。
  如果同时存在则使用Cache-control。

对于强制缓存来说，响应header中会有两个字段来标明失效规则（Expires/Cache-Control)：

**强缓存-expires**

- 该字段是服务器响应消息头字段，告诉浏览器在过期时间之前可以直接从浏览器缓存中存取数据。
- Expires 是 HTTP 1.0 的字段，表示缓存到期时间，**是一个绝对的时间 (当前时间+缓存时间)**。在响应消息头中，设置这个字段之后，就可以告诉浏览器，在未过期之前不需要再次请求。它的值为服务端返回的到期时间，即下一次请求时，请求时间小于服务端返回的到期时间，直接使用缓存数据。
- 由于是绝对时间，用户可能会将客户端本地的时间进行修改，而导致浏览器判断缓存失效，重新请求该资源。此外，即使不考虑修改，时差或者误差等因素也可能造成客户端与服务端的时间不一致，致使缓存失效。
- 优势特点
  - HTTP 1.0 产物，可以在HTTP 1.0和1.1中使用，简单易用。
  - 以时刻标识失效时间。
- 劣势问题
  - 时间是由服务器发送的(UTC)，如果服务器时间和客户端时间存在不一致，可能会出现问题。
  - 存在版本问题，到期之前的修改客户端是不可知的。



**强缓存-cache-control**

- 已知Expires的缺点之后，在HTTP/1.1中，增加了一个字段Cache-control，该字段表示资源缓存的最大有效时间，在该时间内，客户端不需要向服务器发送请求。
- 这两者的区别就是前者是绝对时间，而后者是相对时间。下面列举一些Cache-control字段常用的值：(完整的列表可以查看MDN)
  - max-age：即最大有效时间。
  - must-revalidate：如果超过了max-age的时间，浏览器必须向服务器发送请求，验证资源是否还有效。
  - no-cache：不使用强缓存，需要与服务器验证缓存是否新鲜。
  - no-store: **真正意义上的“不要缓存”**。所有内容都不走缓存，包括强制和对比。
  - public：所有的内容都可以被缓存 (包括客户端和代理服务器， 如 CDN)
  - private：所有的内容只有客户端才可以缓存，代理服务器不能缓存。默认值。
- **Cache-control 的优先级高于 Expires**，为了兼容 HTTP/1.0 和 HTTP/1.1，实际项目中两个字段都可以设置。
- 该字段可以在请求头或者响应头设置，可组合使用多种指令：
  - 可缓存性
    - public：浏览器和缓存服务器都可以缓存页面信息
    - private：default，代理服务器不可缓存，只能被单个用户缓存
    - no-cache：浏览器器和服务器都不应该缓存页面信息，**但仍可缓存，只是在缓存前需要向服务器确认资源是否被更改。**可配合private，过期时间设置为过去时间。
    - only-if-cache：**客户端只接受已缓存的响应**
  - 到期
    - max-age=：缓存存储的最大周期，超过这个周期被认为过期。
    - s-maxage=：设置共享缓存，比如can。会覆盖max-age和expires。
    - max-stale[=]：客户端愿意接收一个已经过期的资源
    - min-fresh=：客户端希望在指定的时间内获取最新的响应
    - stale-while-revalidate=：客户端愿意接收陈旧的响应，并且在后台一部检查新的响应。时间代表客户端愿意接收陈旧响应
      的时间长度。
    - stale-if-error=：如新的检测失败，客户端则愿意接收陈旧的响应，时间代表等待时间。
  - 重新验证和重新加载
    - must-revalidate：如页面过期，则去服务器进行获取。
    - proxy-revalidate：用于共享缓存。
    - immutable：响应正文不随时间改变。
  - 其他
    - no-store：绝对禁止缓存
    - no-transform：不得对资源进行转换和转变。例如，不得对图像格式进行转换。
- 优势特点
  - HTTP 1.1 产物，以时间间隔标识失效时间，解决了Expires服务器和客户端相对时间的问题。
  - 比Expires多了很多选项设置。
- 劣势问题
  - 存在版本问题，到期之前的修改客户端是不可知的。



### 协商缓存

当第一次请求时服务器返回的响应头中没有Cache-Control和Expires或者Cache-Control和Expires过期还或者它的属性设置**为no-cache时**(即**不走强缓存**)，那么浏览器第二次请求时就会与服务器进行协商，与服务器端对比判断资源是否进行了修改更新。

**如果服务器端的资源没有修改，那么就会返回304状态码，告诉浏览器可以使用缓存中的数据**，这样就减少了服务器的数据传输压力。

**如果数据有更新就会返回200状态码**，服务器就会返回更新后的资源并且将缓存信息一起返回。跟协商缓存相关的header头属性有（ETag/If-Not-Match 、Last-Modified/If-Modified-Since）请求头和响应头需要成对出现



### 私有缓存（浏览器级缓存）

私有缓存只能用于单独的用户：Cache-Control: Private



### 共享缓存（代理级缓存）

共享缓存可以被多个用户使用: Cache-Control: Public



---

## 28. 协商缓存原理，谁跟谁协商，如何协商？

协商缓存: 向服务器发送请求，服务器会根据这个请求的request header的一些**参数**来判断是否命中协商缓存，如果命中，则返回304状态码并带上新的response header通知浏览器从缓存中读取资源；

服务器和请求协商，**根据请求头携带的参数进行协商**

协商缓存的HTTP相关头部Last-Modified / If-Modified-Since， **Etag / If-None-Match (优先级比Last-Modified / If-Modified-Since高**)，每次请求需要让服务器判断一下资源是否更新过，从而决定浏览器是否使用缓存，如果是，则返回304，否则重新完整响应。

看一下HTTP缓存的一个总概流程图：
![img](E:\pogject\学习笔记\image\http\1555253303-5b4b22be9160d_articlex)



**协商缓存**

- 协商缓存的状态码由服务器决策返回200或者304
- 当浏览器的强缓存失效的时候或者请求头中设置了不走强缓存，并且在请求头中设置了If-Modified-Since 或者 If-None-Match 的时候，会将这两个属性值到服务端去验证是否命中协商缓存，如果命中了协商缓存，会返回 304 状态，加载浏览器缓存，并且响应头会设置 Last-Modified 或者 ETag 属性。
- 对比缓存在请求数上和没有缓存是一致的，但如果是 304 的话，返回的仅仅是一个状态码而已，并没有实际的文件内容，因此 在响应体体积上的节省是它的优化点。
- 协商缓存有 2 组字段(不是两个)，控制协商缓存的字段有：Last-Modified/If-Modified-since（http1.0）和Etag/If-None-match（http1.1）
- Last-Modified/If-Modified-since表示的是服务器的资源最后一次修改的时间；Etag/If-None-match表示的是服务器资源的唯一标
  识，只要资源变化，Etag就会重新生成。
- Etag/If-None-match的优先级比Last-Modified/If-Modified-since高。

**协商缓存-协商缓存-Last-Modified/If-Modified-since**

- 服务器通过Last-Modified字段告知客户端，**资源最后一次被修改的时间**，例如Last-Modified: Mon, 10 Nov 2018 09:10:11 GMT
- 浏览器将这个值和内容一起记录在缓存数据库中。
- 下一次请求相同资源时时，浏览器从自己的缓存中找出“不确定是否过期的”缓存。因此**在请求头中将上次的Last-Modified的值写入到请求头的If-Modified-Since字段**
- **服务器会将If-Modified-Since的值与Last-Modified字段进行对比**。如果相等，则表示未修改，响应 304；反之，则表示修改了，响应 200 状态码，并返回数据。
- 优势特点
  - 不存在版本问题，每次请求都会去服务器进行校验。服务器对比最后修改时间如果相同则返回304，不同返回200以及资源内容。
- 劣势问题
  - **只要资源修改，无论内容是否发生实质性的变化，都会将该资源返回客户端**。例如周期性重写，这种情况下该资源包含的数据实际上一样的。
  - **以时刻作为标识，无法识别一秒内进行多次修改的情况**。 如果资源更新的速度是秒以下单位，那么该缓存是不能被使用的，因为它的时间单位最低是秒。
  - **某些服务器不能精确的得到文件的最后修改时间**。
  - **如果文件是通过服务器动态生成的，那么该方法的更新时间永远是生成的时间**，尽管文件可能没有变化，所以起不到缓存的作用。

**协商缓存-Etag/If-None-match**

- 为了解决上述问题，出现了一组新的字段Etag和If-None-Match

- Etag**存储的是文件的特殊标识**(一般都是 hash 生成的)，服务器存储着文件的Etag字段。之后的流程和Last-Modified一致，只是Last-Modified字段和它所表示的更新时间改变成了**Etag字段和它所表示的文件 hash**，**把If-Modified-Since变成了If-None-Match**。服务器同样进行比较，命中返回 304, 不命中返回新资源和 200。

- 浏览器在发起请求时，服务器返回在Response header中返回**请求资源的唯一标识**。在下一次请求时，会**将上一次返回的Etag值赋值给If-No-Matched并添加在Request Header中**。服务器将浏览器传来的if-no-matched跟自己的本地的资源的ETag做对比，如果匹配，则返回304通知浏览器读取本地缓存，否则返回200和更新后的资源。

  

**Etag 的优先级高于 Last-Modified**。

- 优势特点

  - **可以更加精确的判断资源是否被修改**，可以识别一秒内多次修改的情况。
  - 不存在版本问题，每次请求都回去服务器进行校验。

- 劣势问题

  - **计算ETag值需要性能损耗**。
  - **分布式服务器存储的情况下，计算ETag的算法如果不一样**，会导致浏览器从一台服务器上获得页面内容后到另外一台服务器上进行验证时现ETag不匹配的情况。
  



### 有了 Last-Modified，为什么还会出现 ETag？

ETag的出现，主要是为了解决 Last-Modified 无法解决的一些问题：

- 某些服务器不能精确得到文件的最后修改时间， 这样就无法通过最后修改时间来判断文件是否更新了。
- 某些文件的修改非常频繁，在秒以下的时间内进行修改. Last-Modified只能精确到秒。
- 一些文件的最后修改时间改变了，但是内容并未改变。 我们不希望客户端认为这个文件修改了。



---

## 29. no-store 和 no-cache 的区别

no-cache 和 no-store 都是 HTTP 协议头 Cache-Control 的值。

区别是：

- no-store

  **彻底禁用缓存**，所有内容都不会被缓存到缓存或临时文件中。

- no-cache

  在浏览器使用缓存前，会往返对比 ETag，如果 ETag 没变，返回 304，则使用缓存。



---

## 30.Cache-Control和expires区别是什么，哪个优先级高

**Cache-Control和expires区别：**

Cache-Control**设置时间长度**

Expires **设置时间点**

**优先级：**

强缓存expires和cache-control同时存在时，**则cache-control会覆盖expires**，expires无论有没有过期，都无效。 即：**cache-control优先级 > expires优先级。**



---

## 31. GET和POST区别

1. get用来**获取数据**，post用来**提交数据**
2. get参数有长度限制（受限于url长度，具体的数值取决于浏览器和服务器的限制，最长2048字节），而post无限制
3. get请求的数据会附加在url之 ，以 " ？ "分割url和传输数据，多个参数用 "&"连接，而post请求会把请求的数据放在http请求体中。
4. 参数类型：post 的参数传递支持更多的数据类型。
5. get是明文传输，post是放在请求体中，**但是开发者可以通过抓包工具看到，也相当于是明文的。**
6. 安全性：Get 请求可以将请求的参数放入 url 中向服务器发送，这样的做法相对于 Post 请求来说，一个方面是不太安全，因为请求的 url 会被保留在历史记录中。**get请求会保存在浏览器历史记录中**，还可能保存在web服务器的日志中
7. 应用场景：GET 请求是一个**幂等**的请求，一般 Get 请求用于对服务器资源不会产生影响的场景，比如说请求一个网页。而 Post **不是一个幂等**的请求，一般用于对服务器资源会产生影响的情景。比如注册用户这一类的操作。
8. 是否缓存：因为不同的应用场景，所以浏览器一般会对 Get 请求缓存，但很少对 Post 请求缓存。
9. 发送的报文格式：Get 请求的报文中实体部分为空，Post 请求的报文中实体部分一般为向服务器发送的数据。

**关于缓存**

缓存一般只适用于那些不会更新服务端数据的请求。

一般 get 请求都是查找请求，不会对服务器资源数据造成修改，而 post 请求一般都会对服务器数据造成修改，所以，**一般会对 get 请求进行缓存**，很少会对 post 请求进行缓存。

 **get 请求是否限制了传参长度？**

- HTTP 协议未规定 GET 和 POST 的长度限制
- GET 的最大长度显示是因为浏览器和 web 服务器限制了 URI 的长度
- 不同的浏览器和 WEB 服务器，限制的最大长度不一样
- 要支持 IE，则最大长度为 2083byte，若只支持 Chrome，则最大长度 8182byte



---

## 32. 怎么用UDP实现可靠传输，两条连接

**参考答案**：

最简单的方式是**在应用层模仿传输层TCP**的可靠性传输。下面不考虑拥塞处理，可靠UDP的简单设计。

- 1、添加seq/ack机制，确保数据发送到对端
- 2、添加发送和接收缓冲区，主要是用户超时重传。
- 3、添加超时重传机制。

详细说明：送端发送数据时，生成一个随机seq=x，然后每一片按照数据大小分配seq。数据到达接收端后接收端放入缓存，并发送一个ack=x的包，表示对方已经收到了数据。发送端收到了ack包后，删除缓冲区对应的数据。时间到后，定时任务检查是否需要重传数据。

目前有如下开源程序利用udp实现了可靠的数据传输。分别为**RUDP、RTP、UDT**。

1、RUDP（Reliable User Datagram Protocol）

***RUDP 提供一组数据服务质量增强机制，如拥塞控制的改进、重发机制及淡化服务器算法等\***，从而在包丢失和网络拥塞的情况下， RTP 客户机（实时位置）面前呈现的就是一个高质量的 RTP 流。在不干扰协议的实时特性的同时，可靠 UDP 的拥塞控制机制允许 TCP 方式下的流控制行为。

2、RTP（Real Time Protocol）

***RTP为数据提供了具有实时特征的端对端传送服务\***，如在组播或单播网络服务下的交互式视频音频或模拟数据。

应用程序通常在 UDP 上运行 RTP 以便使用其多路结点和校验服务；这两种协议都提供了传输层协议的功能。但是 RTP 可以与其它适合的底层网络或传输协议一起使用。如果底层网络提供组播方式，那么 RTP 可以使用该组播表传输数据到多个目的地。

RTP 本身并没有提供按时发送机制或其它服务质量（QoS）保证，它依赖于底层服务去实现这一过程。 RTP 并不保证传送或防止无序传送，也不确定底层网络的可靠性。 RTP 实行有序传送， RTP 中的序列号允许接收方重组发送方的包序列，同时序列号也能用于决定适当的包位置，例如：在视频解码中，就不需要顺序解码。

3、UDT（UDP-based Data Transfer Protocol）

基于UDP的数据传输协议（UDP-basedData Transfer Protocol，简称UDT）是一种互联网数据传输协议。***UDT的主要目的是支持高速广域网上的海量数据传输\***，而互联网上的标准数据传输协议TCP在高带宽长距离网络上性能很差。

顾名思义，UDT建于UDP之上，并引入新的拥塞控制和数据可靠性控制机制。UDT是面向连接的双向的应用层协议。它同时支持可靠的数据流传输和部分可靠的数据报传输。由于UDT完全在UDP上实现，它也可以应用在除了高速数据传输之外的其它应用领域，例如点到点技术（P2P），防火墙穿透，多媒体数据传输等等。



---

## 33. 数据量很大的时候UDP怎么可靠传输

**基于UDP的数据传输协议**（UDP-basedData Transfer Protocol，简称UDT）是一种互联网数据传输协议。***UDT的主要目的是支持高速广域网上的海量数据传输\***，而互联网上的标准数据传输协议TCP在高带宽长距离网络上性能很差。

顾名思义，UDT建于UDP之上，并引入新的拥塞控制和数据可靠性控制机制。UDT是面向连接的双向的应用层协议。它同时支持可靠的数据流传输和部分可靠的数据报传输。由于UDT完全在UDP上实现，它也可以应用在除了高速数据传输之外的其它应用领域，例如点到点技术（P2P），防火墙穿透，多媒体数据传输等等。



---

## 34. TCP断点重传怎么实现的

断点续传的关键是**断点**，所以在制定传输协议的时候要设计好，如下图，我自定义了一个交互协议，**每次下载请求都会带上下载的起始点，这样就可以支持从断点下载了**，其实HTTP里的断点续传也是这个原理，在HTTP的头里有个可选的字段RANGE，表示下载的范围

#### ![img](E:\pogject\学习笔记\image\http\TCP断点重传)



---

## 35. http多个tcp连接怎么实现的？

某些服务器对 Connection: keep-alive 的 Header 进行了支持。意思是说，完成这个 HTTP 请求之后，不要断开 HTTP 请求使用的 TCP 连接。这样的好处是连接可以被重新使用，之后发送 HTTP 请求的时候不需要重新建立 TCP 连接，以及如果维持连接，那么 SSL 的开销也可以避免



---

## 36. keep-alive是什么？

**什么是KeepAlive**

- KeepAlive可以简单理解为**一种状态保持或重用机制**，比如当一条连接建立后，我们不想它立刻被关闭，如果实现了KeepAlive机制，就可以通过它来实现连接的保持
- HTTP的KeepAlive在HTTP 1.0版本默认是关闭的，**但在HTTP1.1是默认开启的**；操作系统里TCP的KeepAlive默认也是关闭，但一般应用都会修改设置来开启。**因此网上TCP流量中基于KeepAlive的是主流**
- HTTP的KeepAlive和TCP的KeepAlive有一定的依赖关系，名称又一样，因此经常被混淆，但其实是不同的东西，下面具体分析一下

**TCP为什么要做KeepAlive**

- 我们都知道TCP的三次握手和四次挥手。当两端通过三次握手建立TCP连接后，就可以传输数据了，数据传输完毕，连接并不会自动关闭，而是一直保持。只有两端分别通过发送各自的FIN报文时，才会关闭自己侧的连接。
- 这个关闭机制看起来简单明了，但实际网络环境千变万化，衍生出了各种问题。假设因为实现缺陷、突然崩溃、恶意攻击或网络丢包等原因，一方一直没有发送FIN报文，则连接会一直保持并消耗着资源，**为了防止这种情况，一般接收方都会主动中断一段时间没有数据传输的TCP连接**，比如LVS会默认中断90秒内没有数据传输的TCP连接，F5会中断5分钟内没有数据传输的TCP连接
- 但有的时候我们的确不希望中断空闲的TCP连接，因为建立一次TCP连接需要经过一到两次的网络交互，且由于TCP的slow start机制，新的TCP连接开始数据传输速度是比较慢的，我们希望通过**连接池模式**，保持一部分空闲连接，**当需要传输数据时，可以从连接池中直接拿一个空闲的TCP连接来全速使用，这样对性能有很大提升**
- 为了支持这种情况，TCP实现了KeepAlive机制。**KeepAlive机制并不是TCP规范的一部分**，但无论Linux和Windows都实现实现了该机制。**TCP实现里KeepAlive默认都是关闭的，且是每个连接单独设置的，**而不是全局设置
- 另外有一个特殊情况就是，当某应用进程关闭后，如果还有该进程相关的TCP连接，一般来说操作系统会自动关闭这些连接



---

## 37. tcp/ip协议栈、网络模型

**TCP/IP 协议栈是一系列网络协议的总和，是构成网络通信的核心骨架**，它定义了电子设备如何连入因特网，以及数据如何在它们之间进行传输。TCP/IP 协议采用4层结构，分别是**应用层、传输层、网络层和链路层**，

`TCP/IP`（`Transmission Control Protocol/Internet Protocol`，传输控制协议/网际协议）是指能够在多个不同网络间实现信息传输的协议簇。TCP/IP协议不仅仅指的是TCP 和IP两个协议，而是指一个由 `FTP、SMTP、TCP、UDP、IP`等协议构成的协议簇， 只是因为在TCP/IP协议中TCP协议和IP协议最具代表性，所以被称为TCP/IP协议。

TCP/IP传输协议是在网络的使用中的最基本的通信协议。TCP/IP传输协议对互联网中各部分进行通信的标准和方法进行了规定。并且，TCP/IP传输协议是保证网络数据信息及时、完整传输的两个重要的协议。TCP/IP传输协议是严格来说是一个四层的体系结构，**应用层** 、**传输层**、**网络层** 和 **数据链路层** 都包含其中。

TCP/IP通讯协议采用了4层的层级结构，每一层都呼叫它的下一层所提供的网络来完成自己的需求。这4层分别为:

- **应用层**: 应用程序间沟通的层，如简单电子邮件传输(SMTP)、文件传输协议(FTP)、网络远程访问协议(Telnet)等。
- **传输层**: 在此层中，它提供了节点间的数据传送，应用程序之间的通信服务，主要功能是数据格式化、数据确认和丢失重传等。如传输控制协议(TCP)、用户数据报协议(UDP)等，TCP和UDP给数据包加入传输数据并把它传输到下一层中，这一层负责传送数据，并且确定数据已被送达并接收。
- **网络层**: 负责提供基本的数据封包传送功能，让每一块数据包都能够到达目的主机(但不检查是否被正确接收)，如网际协议(IP)。
- **数据链路层(主机-网络层)**: 接收IP数据报并进行传输，从网络上接收物理帧，抽取IP数据报转交给下一层，对实际的网络媒体的管理，定义如何使用实际网络(如Ethernet、Serial Line等)来传送数据。



---

## 38. 504 如何排查

排查步骤：

1. 检查500/502/504错误截图，判断是负载均衡问题，高防/安全网络配置问题，还是后端ECS配置问题。
2. 如果有高防/安全网络，请确认高防/安全网络的七层转发配置正确。
3. 请确认是所有客户端都有问题，还仅仅是部分客户端有问题。如果仅仅是部分客户端问题，排查该客户端是否被云盾阻挡，或者负载均衡域名或者IP是否被ISP运营商拦截。
4. 检查负载均衡状态，是否有后端ECS健康检查失败的情况，如果有健康检查失败，解决健康检查失败问题。
5. 在客户端用hosts文件将负载均衡的服务地址绑定到后端服务器的IP地址上，确认是否是后端问题。如果5XX错误间断发生，很可能是后端某一台ECS服务器的配置问题。
6. 尝试将七层负载均衡切换为四层负载均衡，查看问题是否会复现。
7. 检查后端ECS服务器是否存在CPU、内存、磁盘或网络等性能瓶颈。
8. 如果确认是后端服务器问题，请检查后端ECS Web服务器日志是否有相关错误，Web服务是否正常运行，确认Web访问逻辑是否有问题，卸载服务器上杀毒软件重启测试。
9. 检查后端ECS Linux操作系统的TCP内核参数是否配置正确。



---

## 39. tcp 是如何确保有效传输的，拥塞控制

通过以下7种方式确保有效传输

- 校验和
- 序列号
- 确认应答
- 超时重传
- 连接管理
- 流量控制
- 拥塞控制

**TCP 拥塞控制**

TCP不仅可以可以控制端到端的数据传输，还可以对网络上的传输进行监控。这使得TCP非常强大智能，它会根据网络情况来调整自己的收发速度。网络顺畅时就可以发的快，拥塞时就发的相对慢一些。拥塞控制算法主要有四种：**慢启动，拥塞避免，快速重传，快速恢复。**

**慢启动和拥塞避免**
慢启动和拥塞避免算法必须被TCP发送端用来控制正在向网络输送的数据量。为了实现这些算法，必须向TCP每连接状态加入两个参量。

**拥塞窗口**（cwnd）是对发送端收到确认（ACK）之前能向网络传送的最大数据量的一个发送端限制，**接收端通知窗口**（rwnd）是对
未完成数据量的接收端限制。cwnd和rwnd的最小值决定了数据传送。

另一个状态参量，慢启动阀值（ssthresh），被用来确定是用慢启动还是用拥塞避免算法来控制数据传送。

在不清楚环境的情况下向网络传送数据，要求TCP缓慢地探测网络以确定可用流量，避免突然传送大量数据而使网络拥塞。在开始慢启动时cwnd为1，每收到一个用于确认新数据的ACK至多增加SMSS（SENDER MAXIMUM SEGMENT SIZE）字节。

慢启动算法在cwnd<ssthresh时使用。当cwnd和ssthresh相等时，发送端既可以使用慢启动也可以使用拥塞避免。

当拥塞发生时，ssthresh被设置为当前窗口大小的一半（cwnd和接收方通告窗口大小的最小值，但最少为2个报文段）。如果是超时重传，cwnd被设置为1个报文段（这就是慢启动，其实慢启动也不慢，它是指数性增长，只是它的起始比较低）当达到ssthresh时，进入拥塞避免算法（拥塞避免是线性增长）。

**快速重传和快速恢复**

当接收端收到一个顺序混乱的数据，它应该立刻回复一个重复的ACK。这个ACK的目的是通知发送端收到了一个顺序紊乱的数据段，以及期望的序列号。发送端收到这个重复的ACK可能有多种原因，可能丢失或者是网络对数据重新排序等。

**在收到三个重复ACK之后（包含第一次收到的一共四个同样的ACK）**，TCP不等重传定时器超时就重传看起来已经丢失（可能数据绕路并没有丢失）的数据段。因为这个在网络上并没有超时重传那么恶劣，所以不会进入慢启动，**而进入快速恢复**。快速恢复首先会把ssthresh减半(一般还会四舍五入到数据段的倍数)，然后cwnd=ssthresh+收到重复ACK报文段累计的大小。



---

## 40. CDN

CDN的全称是Content Delivery Network，即**内容分发网络**。其目的是通过在现有的internet中增加一层新的网络架构，将网站的内容发布到最接近用户的网络边缘，使用户可以就近取得所需的内容，提高用户访问网站的响应速度。

CDN有别于镜像，因为它比镜像更智能，或者可以做这样一个比喻：CDN=更智能的镜像+缓存+流量导流。因而，CDN可以明显提高Internet网络中信息流动的效率。从技术上全面解决由于网络带宽小、用户访问量大、网点分布不均等问题，提高用户访问网站的响应速度。



---

## 41. 介绍下 HTTPS 中间人攻击

https 协议由 http + ssl 协议构成。

中间人攻击过程如下：

1. 服务器向客户端发送公钥；
2. 攻击者**截获公钥**，保留在自己手上；
3. 然后攻击者自己生成一个【伪造的】公钥，发给客户端；
4. 客户端收到伪造的公钥后，生成加密 hash（秘钥） 值发给服务器；
5. 攻击者获得加密 hash 值，用自己的私钥解密获得真秘钥；
6. 同时生成假的加密 hash 值，发给服务器；
7. 服务器用私钥解密获得假秘钥；
8. 服务器用假秘钥加密传输信息；

防范方法：

**服务器在发送浏览器的公钥中加入 CA 证书**，浏览器可以验证 CA 证书的有效性；（**现有 HTTPS 很难被劫持**，除非信任了劫持者的 CA 证书）。



---

## 42. SSL 连接断开后如何恢复？

**Session ID**

每一次的会话都有一个编号，当对话中断后，下一次重新连接时，只要客户端给出这个编号，服务器如果有这个编号的记录，那么双方就可以继续使用以前的密钥，而不用重新生成一把。

**Session Ticket**

session ticket 是服务器在上一次对话中发送给客户的，这个 ticket 是加密的，只有服务器可能够解密，里面包含了本次会话的信息，比如对话密钥和加密方法等。这样不管我们的请求是否转移到其他的服务器上，当服务器将 ticket 解密以后，就能够获取上次对话的信息，就不用重新生成对话秘钥了。



---

## 43. hosts 文件是什么？

hosts 文件是个没有扩展名的系统文件，其作用就是**将网址域名和其对应的 IP 地址建立一个关联“数据库”**，当用户在浏览器中输入一个 url 时，系统会首先自动从 hosts 文件中寻找对应的 IP 地址。



---

## 44. 同域请求的并发数限制的原因

浏览器的并发请求数目限制是针对同一域名的，**同一时间针对同一域名下的请求有一定数量限制**，超过限制数目的请求会被阻塞（chorme和firefox的限制请求数都是**6个**）。

限制其数量的**原因**是：**基于浏览器端口的限制**和**线程切换开销的考虑**，浏览器为了保护自己不可能无限量的并发请求，如果一次性将所有请求发送到服务器，也会造成服务器的负载上升。



---

## 45. cdn加速原理

1. 当用户点击网站页面上的url时，经过本地dns系统解析，dns系统会将域名的解析权给交cname指向的cdn专用dns服务器。
2. cdn的dns服务器将cdn的全局负载均衡设备ip地址返回给用户。
3. 用户向cdn的全局负载均衡设备发起内容url访问请求。
4. cdn全局负载均衡设备根据用户ip，以及用户请求的内容url，选择一台用户所属区域的区域负载均衡设备
5. **区域负载均衡设备**会为用户选择一台合适的缓存服务器提供服务，选择的依据包括：根据用户IP地址，判断哪一台服务器距用户最近；根据用户所请求的URL中携带的内容名称，判断哪一台服务器上有用户所需内容；查询各个服务器当前的负载情况，判断哪一台服务器尚有服务能力。基于以上这些条件的综合分析之后，区域负载均衡设备会向全局负载均衡设备返回一台缓存服务器的IP地址全局负载均衡设备把服务器的IP地址返回给用户。
6. 用户向缓存服务器发起请求，缓存服务器响应用户请求，将用户所需内容传送到用户终端。如果这台缓存服务器上没有用户想要的内容，而区域均衡设备依然将它分配给了用户，那么这台服务器 就要向它的上一级缓存服务器发起请求内容，直至追溯到网站的源服务器将内容拉回给用户。



---

## 46. 常用的http请求头以及响应头详

**通用首部字段**：请求报文和响应报文两方都会使用的首部

- `Cache-Control` 告诉所有的缓存机制是否可以缓存及哪种类型
- `Connection` 表明是否需要持久连接
- `Transfer-Encoding` 文件传输编码

**Request Header**：

- `Accept` 指定客户端能够接收的内容类型，内容类型中的先后次序表示客户端接收的先后次序
- `Range` 实体的字节范围请求
- `Authorization` web的认证信息
- `Host` 请求资源所在服务器
- `User-Agent` 客户端程序信息

**Response Header**：

- `Location` 令客户端重定向的URI
- `ETag` 能够表示资源唯一资源的字符串
- `Server` 服务器的信息

**实体首部字段**：（Entity头域）

- `Last-Modified` 请求资源的最后修改时间
- `Expires` 响应过期的日期和时间
- `Allow` 资源可支持http请求的方法，不允许则返回405
- Content-Type 返回内容的媒体类型 Content-Type: text/html; charset=utf-8



### **一、常用的http请求头**

**1.Accept**

- **Accept: text/html** 浏览器可以接受服务器回发的类型为 text/html。
- **Accept: \*/\*** 代表浏览器可以处理所有类型,(**一般浏览器发给服务器都是发这个**)。

**2.Accept-Encoding**

- **Accept-Encoding: gzip, deflate** 浏览器**申明自己接收的编码方法，通常指定压缩方法**，是否支持压缩，支持什么压缩方法（gzip，deflate），（注意：这不是指字符编码）。

**3.Accept-Language**

- **Accept-Language:zh-CN,zh;q=0.9** 浏览器申明自己接收的语言。

**4.Connection**

- **Connection: keep-alive** 当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，如果客户端再次访问这个服务器上的网页，会继续使用这一条已经建立的连接。
- **Connection: close** 代表一个Request完成后，客户端和服务器之间用于传输HTTP数据的TCP连接会关闭， 当客户端再次发送Request，需要重新建立TCP连接。

**5.Host（发送请求时，该报头域是必需的）**

- **Host：** 请求报头域主要用于**指定被请求资源的Internet主机和端口号**，它通常从HTTP URL中提取出来的。

**6.Referer**

- **Referer:** 当浏览器向web服务器发送请求的时候，一般会带上Referer，**告诉服务器我是从哪个页面链接过来的**，服务器籍此可以获得一些信息用于处理。

**7.User-Agent**

- **User-Agent: Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36** 告诉HTTP服务器， 客户端使用的操作系统和浏览器的名称和版本。

**8.Cache-Control**

- **Cache-Control:private** 默认为private 响应只能够作为私有的缓存，不能再用户间共享
- **`Cache-Control:public `**响应会被缓存，并且在多用户间共享。正常情况, 如果要求HTTP认证,响应会自动设置为 private.
- **Cache-Control:must-revalidate** 响应在特定条件下会被重用，以满足接下来的请求，但是它必须到服务器端去验证它是不是仍然是最新的。
- **Cache-Control:no-cache** 响应不会被缓存,而是实时向服务器端请求资源。
- **Cache-Control:max-age=10** 设置缓存最大的有效时间，**但是这个参数定义的是时间大小**（比如：60）而不是确定的时间点。单位是[秒 seconds]。
- **Cache-Control:no-store**在任何条件下，响应都不会被缓存，并且不会被写入到客户端的磁盘里**，这也是基于安全考虑的某些敏感的响应才会使用这个。**

**9.Cookie**

**Cookie是用来存储一些用户信息以便让服务器辨别用户身份的**（大多数需要登录的网站上面会比较常见），比如cookie会存储一些用户的用户名和密码，当用户登录后就会在客户端产生一个cookie来存储相关信息，这样浏览器通过读取cookie的信息去服务器上验证并通过后会判定你是合法用户，从而允许查看相应网页。当然cookie里面的数据不仅仅是上述范围，还有很多信息可以存储是cookie里面，比如sessionid等。

**10.Range（用于断点续传）**

- **Range:bytes=0-5** 指定**第一个字节的位置**和**最后一个字节的位置**。用于告诉服务器自己想取对象的哪部分。

### **二、常用的http响应头**

**1.Cache-Control（对应请求中的Cache-Control）**

- **Cache-Control:private** 默认为private 响应只能够作为私有的缓存，不能再用户间共享
- ***\*Cache-Control:public\**** 浏览器和缓存服务器都可以缓存页面信息。
- **Cache-Control:must-revalidate** 对于客户机的每次请求，代理服务器必须想服务器验证缓存是否过时。
- **Cache-Control:no-cache** 浏览器和缓存服务器都不应该缓存页面信息。
- **Cache-Control:max-age=10** 是通知浏览器10秒之内不要烦我，自己从缓冲区中刷新。
- **Cache-Control:no-store** 请求和响应的信息都不应该被存储在对方的磁盘系统中。

**2.Content-Type**

- **Content-Type：text/html;charset=UTF-8** 告诉客户端，资源文件的类型，还有字符编码，客户端通过utf-8对资源进行解码，然后对资源进行html解析。通常我们会看到有些网站是乱码的，往往就是服务器端没有返回正确的编码。

**3.Content-Encoding**

- **Content-Encoding:gzip** 告诉客户端，服务端发送的资源是采用gzip编码的，客户端看到这个信息后，应该采用gzip对资源进行解码。

**4.Date**

- **Date: Tue, 03 Apr 2018 03:52:28 GMT** 这个是服务端发送资源时的服务器时间，GMT是格林尼治所在地的标准时间。http协议中发送的时间都是GMT的，这主要是解决在互联网上，不同时区在相互请求资源的时候，时间混乱问题。

**5.Server**

- **Server：Tengine/1.4.6** 这个是服务器和相对应的版本，只是告诉客户端服务器信息**。**

**6.Transfer-Encoding**

- **Transfer-Encoding：chunked** 这个响应头告诉客户端，服务器发送的资源的方式是分块发送的。**一般分块发送的资源都是服务器动态生成的**，在发送时还不知道发送资源的大小，所以采用分块发送，每一块都是独立的，独立的块都能标示自己的长度，**最后一块是0长度的，当客户端读到这个0长度的块时，就可以确定资源已经传输完了。**

**7.Expires**

- **Expires:Sun, 1 Jan 2000 01:00:00 GMT** 这个响应头也是跟缓存有关的，告诉客户端在这个时间前，可以直接访问缓存副本，很显然这个值会存在问题，因为客户端和服务器的时间不一定会都是相同的，如果时间不同就会导致问题。**所以这个响应头是没有Cache-Control：max-age=*这个响应头准确的**，因为**max-age=date中的date是个相对时间，不仅更好理解，也更准确。**

**8.Last-Modified**

- **Last-Modified: Dec, 26 Dec 2015 17:30:00 GMT** 所请求的对象的最后修改日期(按照 RFC 7231 中定义的“超文本传输协议日期”格式来表示)

**9.Connection**

- **Connection：keep-alive** 这个字段作为回应客户端的Connection：keep-alive，告诉客户端服务器的tcp连接也是一个长连接，客户端可以继续使用这个tcp连接发送http请求。

**10.Etag**

- **ETag: "737060cd8c284d8af7ad3082f209582d"** 就是一个对象（比如URL）的标志值，就一个对象而言，比如一个html文件，如果被修改了，其Etag也会别修改，**所以，ETag的作用跟Last-Modified的作用差不多**，主要供WEB服务器判断一个对象是否改变了。比如前一次请求某个html文件时，获得了其 ETag，当这次又请求这个文件时，浏览器就会把先前获得ETag值发送给WEB服务器，然后WEB服务器会把这个ETag跟该文件的当前ETag进行对比，然后就知道这个文件有没有改变了。

**11.Refresh**

- **Refresh: ** 用于重定向，或者当一个新的资源被创建时。**默认会在5秒后刷新重定向**。

**12.Access-Control-Allow-Origin**

- **Access-Control-Allow-Origin: \*** *号代表所有网站可以跨域资源共享，如果当前字段为`*`那么Access-Control-Allow-Credentials就不能为true
- **Access-Control-Allow-Origin: [www.baidu.com](http://www.baidu.com/)** 指定哪些网站可以跨域资源共享

**13.Access-Control-Allow-Methods**

- **Access-Control-Allow-Methods：GET,POST,PUT,DELETE** 允许哪些方法来访问

**14.Access-Control-Allow-Credentials**

- **Access-Control-Allow-Credentials: true** 是否允许发送cookie。**默认情况下，Cookie不包括在CORS请求之中**。设为true，即表示服务器明确许可，Cookie可以包含在请求中，一起发给服务器。**这个值也只能设为true，如果服务器不要浏览器发送Cookie，删除该字段即可。**如果access-control-allow-origin为*，当前字段就不能为true

**15.Content-Range**

- **Content-Range: bytes 0-5/7877** 指定整个实体中的一部分的插入位置，他也指示了整个实体的长度。在服务器向客户返回一个部分响应，**它必须描述响应覆盖的范围和整个实体长度。**



---

## 47. 什么是粘包问题，如何解决？

默认情况下，TCP 连接会采用延迟传送算法（Nagle 算法），在数据发送之前缓存他们。如果短时间有多个数据发送，会缓冲到一起作一次发送（缓冲大小是socket.bufferSize），这样可以减少 IO 消耗提高性能。（TCP 会出现这个问题，HTTP 协议解决了这个问题）

解决方法

1. 多次发送之前间隔一个等待时间：处理简单，但是影响传输效率；

2. 关闭 Nagle 算法：消耗资源高，整体性能下降；

3. 封包/拆包：使用一些有标识来进行封包拆包（类似 HTTP 协议头尾）；

   

---

## 48. 说说WebSocket和HTTP的区别

### HTTP协议

`HTTP`是单向的，客户端发送请求，服务器发送响应。举例来说，当客户端向服务器发送请求时，该请求以`HTTP`或`HTTPS`的形式发送，在接收到请求后，服务器会将响应发送给客户端。

每个请求都与一个对应的响应相关联，在发送响应后客户端与服务器的连接会被关闭**。每个`HTTP`或`HTTPS`请求每次都会新建与服务器的连接，并且在获得响应后，连接将自行终止。** `HTTP`是在`TCP`之上运行的无状态协议，`TCP`是一种面向连接的协议，它使用三向握手方法保证数据包传输的传递并重新传输丢失的数据包。

`HTTP`可以运行在任何可靠的面向连接的协议（例如`TCP`，`SCTP`）的上层。当客户端将`HTTP`请求发送到服务器时，客户端和服务器之间将打开`TCP`连接，并且在收到响应后，`TCP`连接将终止，每个`HTTP`请求都会建立单独的`TCP`连接到服务器，例如如果客户端向服务器发送10个请求，则将打开10个单独的`HTTP`连接。并在获得响应后关闭。

**理解上面这段关于 `HTTP`的描述时我觉得还要了解一下`HTTP`长连接的概念，以及`HTTP`与`TCP`的关系，简单概括一下就是**：

- `HTTP`协议的长连接和短连接，**实质上是`TCP`协议**的**长连接**和**短连接**。
- 每个`HTTP`连接完成后，其对应的`TCP`连接并不是每次都会关闭。**从 `HTTP/1.1`起，默认使用长连接**，用以保持连接特性。使用长连接的`HTTP`协议，会在响应头有加入这个头部字段：`Connection:keep-alive`
- 在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输`HTTP`数据的`TCP`连接不会关闭，如果客户端再次访问这个服务器上的网页，会继续使用这一条已经建立的连接。**`Keep-Alive`不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如`Apache`，`Nginx`，`Nginx`中这个默认时间是 75s）中设定这个时间**。实现长连接要客户端和服务端都支持长连接。
- `HTTP`属于应用层协议，在传输层使用`TCP`协议，在网络层使用`IP`协议。`IP`协议主要解决网络路由和寻址问题，`TCP`协议主要解决如何在`IP`层之上可靠的传递数据包，使在网络上的另一端收到发端发出的所有包，并且顺序与发出顺序一致。`TCP`有可靠，面向连接的特点。

HTTP消息信息是用`ASCII`编码的，每个`HTTP`请求消息均包含`HTTP`协议版本（`HTTP/1.1`，`HTTP/2`），`HTTP`方法（`GET`/`POST`等），`HTTP`标头（`Content-Type`，`Content-Length`），主机信息等。以及包含要传输到服务器的实际消息的正文（请求主体）。`HTTP`标头的大小从200字节到2`KB`不等，`HTTP`标头的常见大小是700-800字节。当`Web`应用程序在客户端使用更多`cookie`和其他工具扩展代理的存储功能时，它将减少`HTTP`标头的荷载。

![v2-d16648e3fb5ea6405ad0992d732b5246_720w](E:\pogject\学习笔记\image\http\v2-d16648e3fb5ea6405ad0992d732b5246_720w.jpg)

### WebSocket协议

`WebSocket`是双向的，在客户端-服务器通信的场景中使用的全双工协议，与`HTTP`不同，它以`ws://`或`wss://`开头。它是一个有状态协议，这意味着客户端和服务器之间的连接将保持活动状态，直到被任何一方（客户端或服务器）终止。**在通过客户端和服务器中的任何一方关闭连接之后，连接将从两端终止。**

让我们以客户端-服务器通信为例，每当我们启动客户端和服务器之间的连接时，客户端-服务器进行握手随后创建一个新的连接，该连接将保持活动状态，直到被他们中的任何一方终止。建立连接并保持活动状态后，客户端和服务器将使用相同的连接通道进行通信，直到连接终止。

新建的连接被称为`WebSocket`。一旦通信链接建立和连接打开后，消息交换将以双向模式进行，客户端-服务器之间的连接会持续存在。如果其中任何一方（客户端服务器）宕掉或主动关闭连接，则双方均将关闭连接。套接字的工作方式与`HTTP`的工作方式略有不同，状态代码`101`表示`WebSocket`中的交换协议。



![img](https://pic3.zhimg.com/80/v2-60317e56734d6fb8c28840bd8c22a952_720w.jpg)

#### 何时使用WebSocket

- **即时`Web`应用程序**：即时`Web`应用程序使用一个`Web`套接字在客户端显示数据，这些数据由后端服务器连续发送。在`WebSocke`t中，数据被连续推送/传输到已经打开的同一连接中，这就是为什么`WebSocket`更快并提高了应用程序性能的原因。 例如在交易网站或比特币交易中，这是最不稳定的事情，它用于显示价格波动，数据被后端服务器使用Web套接字通道连续推送到客户端。
- **游戏应用程序**：在游戏应用程序中，你可能会注意到，服务器会持续接收数据，而不会刷新用户界面。屏幕上的用户界面会自动刷新，而且不需要建立新的连接，因此在`WebSocket`游戏应用程序中非常有帮助。
- **聊天应用程序**：聊天应用程序仅使用`WebSocket`建立一次连接，便能在订阅户之间交换，发布和广播消息。它重复使用相同的`WebSocket`连接，用于发送和接收消息以及一对一的消息传输。

#### 不能使用WebSocket的场景

如果我们需要通过网络传输的任何实时更新或连续数据流，则可以使用`WebSocket`。如果我们要获取旧数据，或者只想获取一次数据供应用程序使用，则应该使用`HTTP`协议，**不需要很频繁或仅获取一次的数据可以通过简单的`HTTP`请求查询**，因此在这种情况下最好不要使用`WebSocket`。

注意：如果仅加载一次数据，则`RESTful` `Web`服务足以从服务器获取数据。





![img](https://pic3.zhimg.com/80/v2-7473ab83669c31a09c2b2814c7f48fca_720w.jpg)





---

## 49. 你知道哪些应用层协议？

应用层常见的协议：

- 超文本传输 Http、Https
- 文本传输：FTP
- 电子邮件：SMTP、POP3、IMAP
- 动态主机配置：DHCP
- 域名系统：DNS



----

## 50. TCP是怎么判断丢包的？

TCP协议传输的特点主要就是面向字节流、传输可靠、面向连接。

TCP协议保证数据传输可靠性的方式主要有：

- 校验和
- 序列号
- 确认应答
- 超时重传
- 连接管理
- 流量控制
- 拥塞控制

### 确认应答与序列号

序列号：TCP传输时将每个字节的数据都进行了编号，这就是**序列号**。

确认应答：TCP传输的过程中，每次接收方收到数据后，都会对传输方进行确认应答。也就是发送**ACK报文**。这个ACK报文当中带有对应的确认序列号，告诉发送方，接收到了哪些数据，下一次的数据从哪里发。

序列号的作用不仅仅是应答的作用，有了序列号能够将接收到的数据根据序列号排序，并且去掉重复序列号的数据。这也是TCP传输可靠性的保证之一

### 超时重传

在进行TCP传输时，由于确认应答与序列号机制，也就是说发送方发送一部分数据后，都会等待接收方发送的ACK报文，并解析ACK报文，判断数据是否传输成功。如果发送方发送完数据后，迟迟没有等到接收方的ACK报文，这该怎么办呢？而没有收到ACK报文的原因可能是什么呢？

发送方没有接收到ACK响应的原因：其中一方出现了网络问题。

- 数据发送方：数据发送过程中有由于网络问题全体丢包，接收方根本没有收到数据。
- 数据接收方：数据拿到了。但是发送ACK报文的时候由于网络问题，发送失败。

**为了解决丢包问题导致的【确认应答、序列号】机制失效**，**TCP引入了超时重传机制**。简单的理解就是在发送方发送数据后的一段时候内，如果没有接收到接收方的ACK响应，那么刚刚发送的数据需要重新发送。对应上面说到的两种原因，如果是数据发方的问题，数据重新发送，数据接收方进行响应ACK;如果是数据接收方的问题，数据发送过来之后，接收方根据序列号判断是否是重复数据，如果是直接丢弃，然后继续返回ack响应。

那么发送方发送完毕后等待的时间是多少呢？如果这个等待的时间过长，那么会影响TCP传输的整体效率，如果等待时间过短，又会导致频繁的发送重复的包。如何权衡？

由于TCP传输时保证能够在任何环境下都有一个高性能的通信，因此这个**最大超时时间（也就是等待的时间）是动态计算的**。

### 流量控制

接收端在接收到数据后，对其进行处理。如果发送端的发送速度太快，导致接收端的结束缓冲区很快的填充满了。此时如果发送端仍旧发送数据，那么接下来发送的数据都会丢包，继而导致丢包的一系列连锁反应，超时重传呀什么的。而TCP根据接收端对数据的处理能力，决定发送端的发送速度，这个机制就是流量控制。

在TCP协议的报头信息当中，有一个16位字段的窗口大小。在介绍这个窗口大小时我们知道**，窗口大小的内容实际上是接收端接收数据缓冲区的剩余大小**。这个数字越大，证明接收端接收缓冲区的剩余空间越大，网络的吞吐量越大。接收端会在确认应答发送ACK报文时，将自己的即时窗口大小填入，并跟随ACK报文一起发送过去。而发送方根据ACK报文里的窗口大小的值的改变进而改变自己的发送速度。如果接收到窗口大小的值为0，那么发送方将停止发送数据。并定期的向接收端发送窗口探测数据段，让接收端把窗口大小告诉发送端。

### 拥塞控制

TCP传输的过程中，发送端开始发送数据的时候，如果刚开始就发送大量的数据，那么就可能造成一些问题。网络可能在开始的时候就很拥堵，如果给网络中在扔出大量数据，那么这个拥堵就会加剧。拥堵的加剧就会产生大量的丢包，就对大量的超时重传，严重影响传输。

所以TCP引入了慢启动的机制，在开始发送数据时，先发送少量的数据探路。探清当前的网络状态如何，再决定多大的速度进行传输。这时候就引入一个叫做拥塞窗口的概念。发送刚开始定义拥塞窗口为 1，每次收到ACK应答，拥塞窗口加 1。在发送数据之前，首先将拥塞窗口与接收端反馈的窗口大小比对，取较小的值作为实际发送的窗口。

拥塞窗口的增长是指数级别的。慢启动的机制只是说明在开始的时候发送的少，发送的慢，但是增长的速度是非常快的。为了控制拥塞窗口的增长，不能使拥塞窗口单纯的加倍，设置一个拥塞窗口的阈值，当拥塞窗口大小超过阈值时，不能再按照指数来增长，而是线性的增长。在慢启动开始的时候，慢启动的阈值等于窗口的最大值，一旦造成网络拥塞，发生超时重传时，慢启动的阈值会为原来的一半（这里的原来指的是发生网络拥塞时拥塞窗口的大小），同时拥塞窗口重置为 1。



----

## 51.TCP和HTTP请求之间有什么关系？

我们知道开启一个TCP链接之后，HTTP请求就会并行发出。 首先我们来思考一个问题，**浏览器与服务器建立一个TCP链接之后，会不会在完成一个HTTP请求后立马断开？**

- HTTP/1.0的时候是会的，**需要手动设置`Connection: keep-alive`。**
- HTTP/1.1的时候`Connection`默认为`keep-alive` 。

一般情况下，复用的 TCP连接在**等待**设置的**超时**时间之后还没有被任何连接使用的话，就会**主动断开**。

### 一个TCP链接可以对应多少个HTTP请求？

一个TCP链接可以对应多个HTTP请求，**只要这个TCP链接没有断开，就可以发送HTTP请求。**

### 这些HTTP请求可以同时发送，同时响应么，在一个TCP链接中？比如：三个HTTP请求同时发送，同时接收响应。

**在HTTP/1.1中**，单个TCP链接在同一时刻只能处理一个请求，意思就是：**任意两个 HTTP 请求从开始到结束的时间在同一个 TCP链接里不能重叠**。HTTP/1.1 规范中规定了 Pipelining 来试图解决这个问题， 但是浏览器默认关闭了这个功能。

**原因：**

- 一些代理服务器不能正确的处理 HTTP Pipelining。
- 正确的流水线实现是复杂的。
- Head-of-line Blocking 连接头阻塞：在建立起一个 TCP 连接之后，假设客户端在这个连接连续向服务器发送了几个请求。按照标准，服务器应该按照收到请求的顺序返回结果，假设服务器在处理首个请求时花费了大量时间，那么后面所有的请求都需要等着首个请求结束才能响应。

**HTTP/2.0 提供了Multiplexing 多路传输（多路复用）**。可以在一个TCP链接中同时发起多个HTTP请求，同时响应多个HTTP请求。

所以，解决办法也就出现了：

- HTTP/1.1 中可以利用 Pipelining。
- 重用TCP

### 浏览器http请求的并发性是如何体现的？并发请求的数量有没有限制？

有人会说，我们客户端发起HTTP请求明明是异步，并行发送的。怎么到你这里就一个一个发送，一个一个响应了？

其实浏览器会同时与服务器建立多个TCP链接，来支持多个HTTP同时请求的。

就例如：**Chrome浏览器最多允许对同一个域名Host建立6个TCP连接**，不同的浏览器有所区别。

### 补充

关于HTTPS如果图片都是HTTPS的连接，并且在同一域名下，浏览器会先和服务器协商使用`HTTP2`的`Multiplexing`功能进行多路传输，不过未必所有的挂在这个域名下的资源都会使用同一个TCP连接。如果用不了HTTPS或者HTTP2（HTTP2是在HTTPS上实现的），那么浏览器会就在同一个host建立多个TCP连接，每一个TCP连接进行顺序请求资源。



----

## 52. 说说 https 的握手过程,  TLS1.2 握手的过程是怎样的？

https在七层协议里面属于应用层，他基于tcp协议，所以，https握手的过程，一定先经过tcp的三次握手，tcp链接建立好之后，才进入https的对称密钥协商过程，对称密钥协商好之后，就开始正常的收发数据流程。

![img](E:\pogject\学习笔记\image\http\https握手过程)

HTTP 是明文传输的协议，传输保文对外完全透明，非常不安全，那如何进一步保证安全性呢？

由此产生了 `HTTPS`，其实它并不是一个新的协议，而是在 HTTP 下面增加了一层 SSL/TLS 协议，简单的讲，`HTTPS = HTTP + SSL/TLS`。

那什么是 SSL/TLS 呢？

SSL 即安全套接层（Secure Sockets Layer），**在 OSI 七层模型中处于会话层(第 5 层)**。之前 SSL 出过三个大版本，当它发展到第三个大版本的时候才被标准化，成为 **TLS（传输层安全**，Transport Layer Security），并被当做 TLS1.0 的版本，**准确地说，`TLS1.0 = SSL3.1`。**

现在主流的版本是 TLS/1.2, 之前的 TLS1.0、TLS1.1 都被认为是不安全的，在不久的将来会被完全淘汰。

### 传统 RSA 握手

先来说说传统的 TLS 握手，也是大家在网上经常看到的。之所以称它为 RSA 版本，是因为它在加解密`pre_random`的时候采用的是 RSA 算法。

### TLS 1.2 握手过程

现在我们来讲讲主流的 TLS 1.2 版本所采用的方式。

![img](E:\pogject\学习笔记\image\http\TLS握手)

**step 1: Client Hello**

首先，浏览器发送 client_random、TLS版本、加密套件列表。

client_random 是什么？用来最终 secret 的一个参数。

加密套件列表是什么？我举个例子，加密套件列表一般长这样:

```
TLS_ECDHE_WITH_AES_128_GCM_SHA256
```

意思是`TLS`握手过程中，使用`ECDHE`算法生成`pre_random`，128位的`AES`算法进行对称加密，在对称加密的过程中使用主流的`GCM`分组模式，因为对称加密中很重要的一个问题就是如何分组。最后一个是哈希摘要算法，采用`SHA256`算法。

其中值得解释一下的是这个哈希摘要算法，试想一个这样的场景，服务端现在给客户端发消息来了，客户端并不知道此时的消息到底是服务端发的，还是中间人伪造的消息呢？现在引入这个哈希摘要算法，将服务端的证书信息通过`这个算法`生成一个摘要(可以理解为`比较短的字符串`)，用来`标识`这个服务端的身份，用私钥加密后把`加密后的标识`和`自己的公钥`传给客户端。客户端拿到`这个公钥`来解密，生成另外一份摘要。两个摘要进行对比，如果相同则能确认服务端的身份。这也就是所谓`数字签名`的原理。其中除了哈希算法，最重要的过程是`私钥加密，公钥解密`。

**step 2: Server Hello**

可以看到服务器一口气给客户端回复了非常多的内容。

`server_random`也是最后生成`secret`的一个参数, 同时确认 TLS 版本、需要使用的加密套件和自己的证书，这都不难理解。那剩下的`server_params`是干嘛的呢？

现在你只需要知道，`server_random`到达了客户端。

**step 3: Client 验证证书，生成secret**

客户端验证服务端传来的`证书`和`签名`是否通过，如果验证通过，则传递`client_params`这个参数给服务器。

接着客户端通过`ECDHE`算法计算出`pre_random`，其中传入两个参数:`server_params`和`client_params`。现在你应该清楚这个两个参数的作用了吧，由于`ECDHE`基于`椭圆曲线离散对数`，这两个参数也称作`椭圆曲线的公钥`。

客户端现在拥有了`client_random`、`server_random`和`pre_random`，接下来将这三个数通过一个伪随机数函数来计算出最终的`secret`。

**step4: Server 生成 secret**

刚刚客户端不是传了`client_params`过来了吗？

现在服务端开始用`ECDHE`算法生成`pre_random`，接着用和客户端同样的伪随机数函数生成最后的`secret`。

**注意事项**

TLS的过程基本上讲完了，但还有两点需要注意。

第一、实际上 TLS 握手是一个`双向认证`的过程，从 step1 中可以看到，客户端有能力验证服务器的身份，那服务器能不能验证客户端的身份呢？

当然是可以的。具体来说，在 `step3`中，客户端传送`client_params`，实际上给服务器传一个验证消息，让服务器将相同的验证流程(哈希摘要 + 私钥加密 + 公钥解密)走一遍，确认客户端的身份。

第二、当客户端生成`secret`后，会给服务端发送一个收尾的消息，告诉服务器之后的都用对称加密，对称加密的算法就用第一次约定的。服务器生成完`secret`也会向客户端发送一个收尾的消息，告诉客户端以后就直接用对称加密来通信。

这个收尾的消息包括两部分，一部分是`Change Cipher Spec`，意味着后面加密传输了，另一个是`Finished`消息，这个消息是对之前所有发送的数据做的`摘要`，对摘要进行加密，让对方验证一下。

当双方都验证通过之后，握手才正式结束。后面的 HTTP 正式开始传输加密报文。

### RSA 和 ECDHE 握手过程的区别

- ECDHE 握手，也就是主流的 TLS1.2 握手中，使用`ECDHE`实现`pre_random`的加密解密，没有用到 RSA。
- 使用 ECDHE 还有一个特点，就是客户端发送完收尾消息后可以提前`抢跑`，直接发送 HTTP 报文，节省了一个 RTT，不必等到收尾消息到达服务器，然后等服务器返回收尾消息给自己，直接开始发请求。这也叫`TLS False Start`。





----

## 53. HTTP2中，多路复用的原理是什么？

HTTP/2是一个二进制协议，其基于“帧”的结构设计，改进了很多HTTP/1.1痛点问题。

### 什么是多路复用？

![img](E:\pogject\学习笔记\image\http\多路复用)

HTTP/1.1协议的请求-响应模型大家都是熟悉的，我们用“HTTP消息”来表示一个请求-响应的过程，那么HTTP/1.1中的消息是“管道串形化”的：只有等一个消息完成之后，才能进行下一条消息；而HTTP/2中多个消息交织在了一起，这无疑提高了“通信”的效率。这就是多路复用：在一个HTTP的连接上，多路“HTTP消息”同时工作。

### 为什么 `HTTP/1.1` 不能实现“多路复用”？

简单回答就是：`HTTP/2` 是基于二进制“帧”的协议，HTTP/1.1是基于“文本分割”解析的协议。

`HTTP/1.1` 发送请求消息的文本格式：以换行符分割每一条 `key:value` 的内容，解析这种数据用不着什么高科技，相反的，解析这种数据往往速度慢且容易出错。“服务端”需要不断的读入字节，直到遇到分隔符（这里指换行符，代码中可能使用/n或者/r/n表示），这种解析方式是可行的，并且 `HTTP/1.1` 已经被广泛使用了二十多年，这事已经做过无数次了，问题一直都是存在的：

- 一次只能处理一个请求或响应，因为这种以分隔符分割消息的数据，在完成之前不能停止解析。
- 解析这种数据无法预知需要多少内存，这会带给“服务端”很大的压力，因为它不知道要把一行要解析的内容读到多大的“缓冲区”中，在保证解析效率和速度的前提下：内存该如何分配？

### HTTP/2帧结构设计和多路复用实现

前边提到：HTTP/2设计是基于“二进制帧”进行设计的，这种设计无疑是一种“高超的艺术”，因为它实现了一个目的：一切可预知，一切可控。

帧是一个数据单元，实现了对消息的封装。下面是HTTP/2的帧结构：



![img](E:\pogject\学习笔记\image\http\8fe47b4911b19748e3f93aeeadb848b7.png)



帧的字节中保存了不同的信息，前9个字节对于每个帧都是一致的，“服务器”解析HTTP/2的数据帧时只需要解析这些字节，就能准确的知道整个帧期望多少字节数来进行处理信息。

如果使用HTTP/1.1的话，你需要发送完上一个请求，才能发送下一个；由于HTTP/2是分帧的，请求和响应可以交错甚至可以复用。 为了能够发送不同的“数据信息”，通过帧数据传递不同的内容，HTTP/2中定义了10种不同类型的帧。

有了以上对HTTP/2帧的了解，我们就可以解释多路复用是怎样实现的了，不过在这之前我们先来了解“流”的概念：HTTP/2连接上独立的、双向的帧序列交换。流ID（帧首部的6-9字节）用来标识帧所属的流

下面两张图分别表示了HTTP/2协议上POST请求数据流“复用”的过程，很容易看的明白：

![img](E:\pogject\学习笔记\image\http\a3635c2cbf688a5437ac91257df43b68.png)



----

## 54. Cache-Control 有哪些常见配置值？

Cache-Control的值有十几种，其中包含了请求首部可携带的和响应首部携带的。

咱们先看看 **request首部** Cache-Control的值

- no-cache

当客户端请求时携带这个首部字段的时候，通过中间的缓存服务器时，会不去拿缓存资源，而是让中间服务器转发给资源服务器，资源服务器看看一下这个资源过期没有，如果没有就会告知中间服务器，可以使用缓存资源。否则资源服务器就会直接返回新的资源。

- no-store

这个字段非常有意思，就是告知服务器或者客户端以及中间服务器，我请求或者响应的内容里面有机密信息，这些响应的内容是永远不会得到响应的。

- max-age

`max-age`指令标示了客户端不愿意接收一个`age`大于设定时间的响应，这个字段表达是最大缓存时长，请求中单单添加这个字段，实现不了缓存时长，必须结合响应的max-age。一会，会在响应中的max-age 详细说明

- max-stale

**这个指令表达的是缓存时长过期以后，还可以有效**。比如现在max-age：60秒，那么max-stale：60秒，现在的缓存时长就是120秒，

- min-fresh

设定能够容忍的**最小新鲜度（缓存时长）**。`min-fresh`标示了客户端不愿意接受**新鲜度**不多于当前的`age`加上`min-fresh`设定的时间之和的响应。

- no-transfrom

使用 no-transform 指令规定无论是在请求还是响应中，缓存都不能改 变实体主体的媒体类型。

- only-if-cache

使用 only-if-cached 指令表示客户端仅在缓存服务器本地缓存目标资源的情况下，才会要求其返回。换言之，该指令要求缓存服务器不重新加载响应，也不会再次确认资源有效性。若发生请求缓存服务器的本 地缓存无响应，则返回状态码 504 Gateway Timeout。

- cache-extension

通过 cache-extension 标记（token），可以扩展 Cache-Control 首部字 段内的指令。

咱们再看看 **response首部** Cache-Control的值

- pulic

这个字段和private是相对的，Cache-Control: public时，则表明所有的用户在通过缓存服务器的时候，都可以缓存这个资源。

- private

这个字段和pulic是相对的，Cache-Control: private时，则表明只有某个在通过缓存服务器的时候，得到缓存资源

- no-cache

如果服务器返回的响应中包含 no-cache 指令，那么缓存服务器不能对 资源进行缓存。源服务器以后也将不再对缓存服务器请求中提出的资 源有效性进行确认，且禁止其对响应资源进行缓存操作。

- no-store

同请求首部的no-store指令一样

- no-transfrom

同请求首部的no-transfrom指令一样

- max-age

在Response中设置max-age的时间信息，可以在客户端生成缓存文件，在缓存不过期的情况下，客户端不会直接向服务器请求数据，在缓存过期的情况下，客户端会向服务器直接请求生成新的缓存。

如果同时设置了Response和Request中的max-age 缓存时间，如果Request中的max-age时间小于Response中的max-age时间，客户端会根据Request中max-age时间周期去直接进行网络请求，如果碰到断网或者网络请求不通的情况，即使缓存还在有效期内（Response中设置的max-age时间足够大），在Request设置的max-age过期之后，APP也会直接去进行网络请求。 **因此可以考虑在客户端的设计中一个和好的网络缓存场景，用Response的max-age控制缓存的时间，用Request中max-age控制刷新的时间和机制**

**应用 HTTP/1.1 版本的缓存服务器遇到同时存在 Expires 首部字段的情 况时，会优先处理 max-age 指令，而忽略掉 Expires 首部字段。而 HTTP/1.0 版本的缓存服务器的情况却相反，max-age 指令会被忽略**

- s-max-age

和max-age类似，它们的不同点是 s- maxage 指令只适用于供多位用户使用的公共缓存服务器

- must-revalidate

使用 must-revalidate 指令，代理会向源服务器再次验证即将返回的响 应缓存目前是否仍然有效。

若代理无法连通源服务器再次获取有效资源的话，缓存必须给客户端 一条 504（Gateway Timeout）状态码。

另外，使用 must-revalidate 指令会忽略请求的 max-stale 指令（即使已 经在首部使用了 max-stale，也不会再有效果）。

- proxy-revalidate

proxy-revalidate 指令要求所有的缓存服务器在接收到客户端带有该指 令的请求返回响应之前，必须再次验证缓存的有效性。

- cache-extension

同请求首部的cache-extension指令一样



----

## 55.说说你对“三次握手”、“四次挥手”的理解

我们都知道TCP是面向连接的，`三次握手`就是用来建立连接的，`四次握手`就是用来断开连接的。

### 三次握手





![img](E:\pogject\学习笔记\image\http\f0273720170a42d9887b4aaba58035da~tplv-k3u1fbpfcp-zoom-1.image)



我们来看一下三次握手的过程：

- 一开始，客户端和服务端都处于 `CLOSED` 状态。客户端主动打开连接，服务端被动打卡连接，结束`CLOSED` z状态，开始监听，进入 `LISTEN `状态。

**一次握手**

- 客户端会随机初始化序号（`client_isn`），将此序号置于 TCP 首部的「序号」字段中，同时把 `SYN` 标志位置为 `1` ，表示 `SYN` 报文。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于 `SYN-SENT` 状态。

**二次握手**

- 服务端收到客户端的 `SYN` 报文后，首先服务端也随机初始化自己的序号（`server_isn`），将此序号填入 TCP 首部的「序号」字段中，其次把 TCP 首部的「确认应答号」字段填入 `client_isn + 1`, 接着把 `SYN` 和 `ACK` 标志位置为 `1`。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 `SYN-RCVD` 状态。

**三次握手**

- 客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文 TCP 首部 `ACK` 标志位置为 `1` ，其次「确认应答号」字段填入 `server_isn + 1` ，最后把报文发送给服务端，这次报文可以携带客户到服务器的数据，之后客户端处于 `ESTABLISHED` 状态。

好了，经过三次握手的过程，客户端和服务端之间的确定连接正常，接下来进入`ESTABLISHED`状态，服务端和客户端就可以快乐地通信了。

这里有个动态过程的图示：



![img](E:\pogject\学习笔记\image\http\d9b637ad47394ae286a51971b7d1567e~tplv-k3u1fbpfcp-zoom-1.image)



这里有个小细节，第三次握手是可以携带数据的，这是面试常问的点。

> **那么为什么要三次握手呢？两次不行吗？**

- 为了防止服务器端开启一些无用的连接增加服务器开销
- 防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误。

由于网络传输是有延时的(要通过网络光纤和各种中间代理服务器)，在传输的过程中，比如客户端发起了 SYN=1 的第一次握手。

如果服务器端就直接创建了这个连接并返回包含 SYN、ACK 和 Seq 等内容的数据包给客户端，这个数据包因为网络传输的原因丢失了，丢失之后客户端就一直没有接收到服务器返回的数据包。

如果没有第三次握手告诉服务器端客户端收的到服务器端传输的数据的话，服务器端是不知道客户端有没有接收到服务器端返回的信息的。服务端就认为这个连接是可用的，端口就一直开着，等到客户端因超时重新发出请求时，服务器就会重新开启一个端口连接。

这样一来，就会有很多无效的连接端口白白地开着，导致资源的浪费。

这个过程可理解为：



![img](E:\pogject\学习笔记\image\http\eb39cfdf399c421aa1698fcff641be98~tplv-k3u1fbpfcp-zoom-1.image)



还有一种情况是已经失效的客户端发出的请求信息，由于某种原因传输到了服务器端，服务器端以为是客户端发出的有效请求，接收后产生错误。



![img](E:\pogject\学习笔记\image\http\defd894c70c24c3aadb0aad77d648105~tplv-k3u1fbpfcp-zoom-1.image)



所以我们需要“第三次握手”来确认这个过程：

通过第三次握手的数据告诉服务端，客户端有没有收到服务器“第二次握手”时传过去的数据，以及这个连接的序号是不是有效的。若发送的这个数据是“`收到且没有问题`”的信息，接收后服务器就正常建立 TCP 连接，否则建立 TCP 连接失败，服务器关闭连接端口。由此减少服务器开销和接收到失效请求发生的错误。

### 四次挥手



![img](E:\pogject\学习笔记\image\http\0e0aa33202914929aef538432fece844~tplv-k3u1fbpfcp-zoom-1.image)



聚散终有时，TCP 断开连接是通过**四次挥手**方式。

`双方`都可以主动断开连接，断开连接后主机中的「资源」将被释放。

上图是客户端主动关闭连接 ：

**一次挥手**

- 客户端打算关闭连接，此时会发送一个 TCP 首部 `FIN` 标志位被置为 `1` 的报文，也即 `FIN` 报文，之后客户端进入 `FIN_WAIT_1` 状态。

**二次挥手**

- 服务端收到该报文后，就向客户端发送 `ACK` 应答报文，接着服务端进入 `CLOSED_WAIT` 状态。

**三次挥手**

- 客户端收到服务端的 `ACK` 应答报文后，之后进入 `FIN_WAIT_2` 状态。等待服务端处理完数据后，也向客户端发送 `FIN` 报文，之后服务端进入 `LAST_ACK` 状态。

**四次挥手**

- 客户端收到服务端的 `FIN` 报文后，回一个 `ACK` 应答报文，之后进入 `TIME_WAIT` 状态
- 服务器收到了 `ACK` 应答报文后，就进入了 `CLOSED` 状态，至此服务端已经完成连接的关闭。
- 客户端在经过 `2MSL` 一段时间后，自动进入 `CLOSED` 状态，至此客户端也完成连接的关闭。

你可以看到，每个方向都需要**一个 FIN 和一个 ACK**，因此通常被称为**四次挥手**。

> **为什么要挥手四次？**

再来回顾下四次挥手双方发 `FIN` 包的过程，就能理解为什么需要四次了。

- 关闭连接时，客户端向服务端发送 `FIN` 时，仅仅表示客户端不再发送数据了但是还能接收数据。
- 服务器收到客户端的 `FIN` 报文时，先回一个 `ACK` 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 `FIN` 报文给客户端来表示同意现在关闭连接。

从上面过程可知，服务端通常需要等待完成数据的发送和处理，所以服务端的 `ACK` 和 `FIN` 一般都会分开发送，从而比三次握手导致多了一次。

> **为什么客户端在TIME-WAIT阶段要等2MSL？**

为的是确认服务器端是否收到客户端发出的 ACK 确认报文，当客户端发出最后的 ACK 确认报文时，并不能确定服务器端能够收到该段报文。

所以客户端在发送完 ACK 确认报文之后，会设置一个时长为 2MSL 的计时器。

MSL 指的是 **Maximum Segment Lifetime**：一段 TCP 报文在传输过程中的最大生命周期。

2MSL 即是服务器端发出为 FIN 报文和客户端发出的 ACK 确认报文所能保持有效的最大时长。

服务器端在 1MSL 内没有收到客户端发出的 ACK 确认报文，就会再次向客户端发出 FIN 报文：

- 如果客户端在 2MSL 内，再次收到了来自服务器端的 FIN 报文，说明服务器端由于各种原因没有接收到客户端发出的 ACK 确认报文。

客户端再次向服务器端发出 ACK 确认报文，计时器重置，重新开始 2MSL 的计时。

- 否则客户端在 2MSL 内没有再次收到来自服务器端的 FIN 报文，说明服务器端正常接收了 ACK 确认报文，客户端可以进入 CLOSED 阶段，完成“四次挥手”。

所以，客户端要经历时长为 2SML 的 TIME-WAIT 阶段;这也是为什么客户端比服务器端晚进入 CLOSED 阶段的原因。

这里同样有个动态过程的图示：



![img](E:\pogject\学习笔记\image\http\290fd6de63004c7396029b6d861bfe39~tplv-k3u1fbpfcp-zoom-1.image)



----

## 56. 为什么推荐将静态资源放到cdn上？

### 静态资源是什么

#### 静态资源

静态资源是**指在不同请求中访问到的数据都相同的静态文件**。例如：图片、视频、网站中的文件（html、css、js）、软件安装包、apk文件、压缩包文件等。

#### 动态资源

动态资源是**指在不同请求中访问到的数据不相同的动态内容**。例如：网站中的文件（asp、jsp、php、perl、cgi）、API接口、数据库交互请求等。

### CDN是什么

内容分发网络，Content Delivery Network或Content Ddistribute Network，简称CDN，是建立并覆盖在承载网之上，由分布在不同区域的边缘节点服务器群组成的分布式网络。

**CDN加速的本质是缓存加速**。将服务器上存储的静态内容缓存在CDN节点上，当访问这些静态内容时，无需访问服务器源站，就近访问CDN节点即可获取相同内容，从而达到加速的效果，同时减轻服务器源站的压力。

**CDN应用广泛，解决因分布、带宽、服务器性能带来的访问延迟问题，适用于站点加速、点播、直播等场景**。使用户可就近取得所需内容，解决 Internet网络拥挤的状况，提高用户访问网站的响应速度和成功率。

由于访问动态内容时，每次都需要访问服务器，由服务器动态生成实时的数据并返回。**因此CDN的缓存加速不适用于加速动态内容**，CDN无法缓存实时变化的动态内容。对于动态内容请求，CDN节点只能转发回服务器源站，没有加速效果。

### CDN的作用

**1. 加速网站的访问**

**2. 为了实现跨运营商、跨地域的全网覆盖**

互联不互通、区域ISP地域局限、出口带宽受限制等种种因素都造成了网站的区域性无法访问。CDN加速可以覆盖全球的线路，通过和运营商合作，部署IDC资源，在全国骨干节点商，合理部署CDN边缘分发存储节点，充分利用带宽资源，平衡源站流量。

**3. 为了保障你的网站安全**

CDN的负载均衡和分布式存储技术，可以加强网站的可靠性，相当无无形中给你的网站添加了一把保护伞，应对绝大部分的互联网攻击事件。**防攻击系统也能避免网站遭到恶意攻击。**

**4. 为了异地备援**

当某个服务器发生意外故障时，系统将会调用其他临近的健康服务器节点进行服务，进而提供接近100%的可靠性，这就让你的网站可以做到永不宕机。

**5. 为了节约成本投入**

使用CDN加速可以实现网站的全国铺设，你根据不用考虑购买服务器与后续的托管运维，服务器之间镜像同步，也不用为了管理维护技术人员而烦恼，节省了人力、精力和财力。

**6. 为了让你更专注业务本身**

CDN加速厂商一般都会提供一站式服务，业务不仅限于CDN，还有配套的云存储、大数据服务、视频云服务等，而且一般会提供7x24运维监控支持，保证网络随时畅通，你可以放心使用。并且将更多的精力投入到发展自身的核心业务之上。

### CDN工作原理



![img](E:\pogject\学习笔记\image\http\f8402497bd0349aaac7825a2335eb72b~tplv-k3u1fbpfcp-watermark.image)



- 当用户点击网站页面上的内容URL，经过本地DNS系统解析，DNS系统会最终将域名的解析权交给CNAME指向的CDN专用DNS服务器。
- CDN的DNS服务器将CDN的全局负载均衡设备IP地址返回用户。
- 用户向CDN的全局负载均衡设备发起内容URL访问请求。
- CDN全局负载均衡设备根据用户IP地址，以及用户请求的内容URL，选择一台用户所属区域的区域负载均衡设备，告诉用户向这台设备发起请求。
- 区域负载均衡设备会为用户选择一台合适的缓存服务器提供服务，选择的依据包括：根据用户IP地址，判断哪一台服务器距用户最近；根据用户所请求的URL中携带的内容名称，判断哪一台服务器上有用户所需内容；查询各个服务器当前的负载情况，判断哪一台服务器尚有服务能力。基于以上这些条件的综合分析之后，区域负载均衡设备会向全局负载均衡设备返回一台缓存服务器的IP地址。
- 全局负载均衡设备把服务器的IP地址返回给用户。
- 用户向缓存服务器发起请求，缓存服务器响应用户请求，将用户所需内容传送到用户终端。如果这台缓存服务器上并没有用户想要的内容，而区域均衡设备依然将它分配给了用户，那么这台服务器就要向它的上一级缓存服务器请求内容，直至追溯到网站的源服务器将内容拉到本地。

DNS服务器根据用户IP地址，将域名解析成相应节点的缓存服务器IP地址，实现用户就近访问。使用CDN服务的网站，只需将其域名解析权交给CDN的GSLB设备，将需要分发的内容注入CDN，就可以实现内容加速了。

### 当没有CDN时

今天我们看到的网站系统基本上都是基于B/S架构的。B/S架构，即Browser-Server（浏览器 服务器）架构。

用户通过浏览器等方式访问网站的过程：

- 用户在自己的浏览器中输入要访问的网站域名。
- 浏览器向本地DNS服务器请求对该域名的解析。
- 本地DNS服务器中如果缓存有这个域名的解析结果，则直接响应用户的解析请求。
- 本地DNS服务器中如果没有关于这个域名的解析结果的缓存，则以递归方式向整个DNS系统请求解析，获得应答后将结果反馈给浏览器。
- 浏览器得到域名解析结果，就是该域名相应的服务设备的IP地址。
- 浏览器向服务器请求内容。
- 服务器将用户请求内容传送给浏览器。



----

## 57. 介绍下304过程

首先304状态码是对客户端有缓存情况下服务端的一种响应。

客户端在请求一个文件的时候，发现自己缓存的文件有 `Last Modified` ，那么在请求中会包含 `If Modified Since` ，这个时间就是缓存文件的 Last Modified 。

因此，如果请求中包含 `If Modified Since`，就说明已经有缓存在客户端。服务端只要判断这个时间和当前请求的文件的修改时间就可以确定是返回 304 还是 200 。

对于静态文件，例如：CSS、图片，服务器会自动完成 Last Modified 和 If Modified Since 的比较，完成缓存或者更新。但是对于动态页面，就是动态产生的页面，往往没有包含 Last Modified 信息，这样浏览器、网关等都不会做缓存，也就是在每次请求的时候都完成一个 200 的请求。

因此，对于动态页面做缓存加速，首先要在 Response 的 HTTP Header 中增加 Last Modified 定义，其次根据 Request 中的 `If Modified Since` 和被请求内容的更新时间来返回 200 或者 304 。虽然在返回 304 的时候已经做了一次数据库查询，但是可以避免接下来更多的数据库查询，并且没有返回页面内容而只是一个 HTTP Header，从而大大的降低带宽的消耗，对于用户的感觉也是提高。

通常来说,缓存是个好东西.如果你想提高自己网站的访问速度,缓存是必须要考虑的。可是在调试的时候,有时候需要阻止缓存,这样才能确保你所访问到的资源是最新的。



---

## 58. 301、302、303、307、308 这些状态码有什么区别？

3xx开头的状态码都表示重定向。

先说明一些版本问题， 301和302都是http1.0就定义好的，在http1.1中才新增了其余的状态码。

### 301 Moved Permanently 永久重定向

> 在请求的 URL 已被移除时使用。响应的 Location 首部中应该包含 资源现在所处的 URL。

默认情况下，永久重定向是会被浏览器缓存的。

### 302 Found 临时重定向

> 与 301 状态码类似；但是，客户端应该使用 Location 首部给出的 URL 来临时定位资源。将来的请求仍应使用老的 URL。

**在浏览器的实现中，302默认以get重新发出请求**。比如以post访问 a.com ,用302重定向到b.com，浏览器会使用get请求b.com。但这样就会导致之前的post请求数据丢失，**相对的 307不允许修改请求方法**，这也是302和307最大的区别

在post数据量大的情况下从post改为get，肯定会丢失很多参数。但是很多浏览器都是以get方式重定向的，所以在后来的[rfc7231](https://tools.ietf.org/html/rfc7231#section-6.4.4) 中取消了这一段强制要求，并将此要求放在了307状态码中。

### 303 See Other 临时重定向

303 是为了区分302而存在的。

虽然 [RFC 1945](https://tools.ietf.org/html/rfc1945) 和 [RFC 2068](https://tools.ietf.org/html/rfc2068) 规范不允许客户端在重定向时改变请求的方法，但是很多现存的浏览器在收到302响应时，直接使用GET方式访问在Location中规定的URI，而无视原先请求的方法。因此状态码303被添加了进来，用以明确服务器期待客户端进行何种反应。 

重定向到新地址时，客户端必须使用GET方法请求新地址。

### 307 Temporary Redirect

这个状态码和302相似，有一个唯一的区别是不允许将请求方法从post改为get。

### 308 Permanent Redirect 永久重定向

[rfc7538](https://tools.ietf.org/html/rfc7538) 新增的状态码

> 此状态码类似于301（永久移动），但不允许更改从POST到GET的请求方法。

308是307的永久版本，和307是一对

**永久重定向**有两个： 301和308。

- 两者都默认缓存，
- 但是308不允许将请求方法从POST修改到GET, 301允许。

**临时重定向**三个：302，303，307

- 303强制浏览器可以将请求方法从POST修改到GET
- 307不允许浏览器修改请求方法。
- 302一开始的标准是不允许修改POST方法，但是浏览器的实现不遵循标准，标准就向现实妥协而做了修改。



---

## 59. TLS 1.3 做了哪些改进？

TLS 1.2 虽然存在了 10 多年，经历了无数的考验，但历史的车轮总是不断向前的，为了获得更强的安全、更优秀的性能，在2018年就推出了 TLS1.3，对于TLS1.2做了一系列的改进，主要分为这几个部分:强化安全、提高性能。

TLS1.3 在 TLS1.2 的基础上废除了大量的算法，提升了安全性。同时利用会话复用节省了重新生成密钥的时间，利用 PSK 做到了`0-RTT`连接。

### 强化安全

在 TLS1.3 中废除了非常多的加密算法，最后只保留五个加密套件:

- TLS_AES_128_GCM_SHA256
- TLS_AES_256_GCM_SHA384
- TLS_CHACHA20_POLY1305_SHA256
- TLS_AES_128_GCM_SHA256
- TLS_AES_128_GCM_8_SHA256

可以看到，最后剩下的对称加密算法只有 `AES` 和 `CHACHA20`，之前主流的也会这两种。分组模式也只剩下 `GCM` 和 `POLY1305`, 哈希摘要算法只剩下了 `SHA256` 和 `SHA384` 了。

那你可能会问了, 之前`RSA`这么重要的非对称加密算法怎么不在了？

可能有两方面的原因:

- 2015年发现了`FREAK`攻击，即已经有人发现了 RSA 的漏洞，能够进行破解了。
- 一旦私钥泄露，那么中间人可以通过私钥计算出之前所有报文的`secret`，破解之前所有的密文。

为什么？回到 RSA 握手的过程中，客户端拿到服务器的证书后，提取出服务器的公钥，然后生成`pre_random`并用`公钥`加密传给服务器，服务器通过`私钥`解密，从而拿到真实的`pre_random`。当中间人拿到了服务器私钥，并且截获之前所有报文的时候，那么就能拿到`pre_random`、`server_random`和`client_random`并根据对应的随机数函数生成`secret`，也就是拿到了 TLS 最终的会话密钥，每一个历史报文都能通过这样的方式进行破解。

但`ECDHE`在每次握手时都会生成临时的密钥对，即使私钥被破解，之前的历史消息并不会受到影响。这种一次破解并不影响历史信息的性质也叫`前向安全性`。

`RSA` 算法不具备前向安全性，而 `ECDHE` 具备，因此在 TLS1.3 中彻底取代了`RSA`。

### 提升性能

#### 握手改进

流程如下:



![img](E:\pogject\学习笔记\image\http\TLS3握手)



大体的方式和 TLS1.2 差不多，不过和 TLS 1.2 相比少了一个 RTT， 服务端不必等待对方验证证书之后才拿到`client_params`，而是直接在第一次握手的时候就能够拿到, 拿到之后立即计算`secret`，节省了之前不必要的等待时间。同时，这也意味着在第一次握手的时候客户端需要传送更多的信息，一口气给传完。

这种 TLS 1.3 握手方式也被叫做`1-RTT握手`。但其实这种`1-RTT`的握手方式还是有一些优化的空间的。

#### 会话复用

会话复用有两种方式: `Session ID`和`Session Ticket`。

先说说最早出现的`Seesion ID`，具体做法是客户端和服务器首次连接后各自保存会话的 ID，并存储会话密钥，当再次连接时，客户端发送`ID`过来，服务器查找这个 ID 是否存在，如果找到了就直接复用之前的会话状态，会话密钥不用重新生成，直接用原来的那份。

但这种方式也存在一个弊端，就是当客户端数量庞大的时候，对服务端的存储压力非常大。

因而出现了第二种方式——`Session Ticket`。它的思路就是: 服务端的压力大，那就把压力分摊给客户端呗。具体来说，双方连接成功后，服务器加密会话信息，用`Session Ticket`消息发给客户端，让客户端保存下来。下次重连的时候，就把这个 Ticket 进行解密，验证它过没过期，如果没过期那就直接恢复之前的会话状态。

这种方式虽然减小了服务端的存储压力，但与带来了安全问题，即每次用一个固定的密钥来解密 Ticket 数据，一旦黑客拿到这个密钥，之前所有的历史记录也被破解了。**因此为了尽量避免这样的问题，密钥需要定期进行更换。**

总的来说，这些会话复用的技术在保证`1-RTT`的同时，也节省了生成会话密钥这些算法所消耗的时间，是一笔可观的性能提升。

#### PSK

刚刚说的都是`1-RTT`情况下的优化，那能不能优化到`0-RTT`呢？

答案是可以的。做法其实也很简单，在发送`Session Ticket`的同时带上应用数据，不用等到服务端确认，这种方式被称为`Pre-Shared Key`，即 PSK。

这种方式虽然方便，但也带来了安全问题。中间人截获`PSK`的数据，不断向服务器重复发，类似于 TCP 第一次握手携带数据，增加了服务器被攻击的风险。



----

## 60. 如何理解 HTTP 代理？

我们知道在 HTTP 是基于`请求-响应`模型的协议，一般由客户端发请求，服务器来进行响应。

当然，也有特殊情况，就是代理服务器的情况。引入代理之后，作为代理的服务器相当于一个中间人的角色，对于客户端而言，表现为服务器进行响应；而对于源服务器，表现为客户端发起请求，具有`双重身份`。

那代理服务器到底是用来做什么的呢？

### 功能

- `负载均衡`。客户端的请求只会先到达代理服务器，后面到底有多少源服务器，IP 都是多少，客户端是不知道的。因此，这个代理服务器可以拿到这个请求之后，可以通过特定的算法分发给不同的源服务器，让各台源服务器的负载尽量平均。当然，这样的算法有很多，包括`随机算法`、`轮询`、`一致性hash`、`LRU(最近最少使用)`等等
- `保障安全`。利用`心跳`机制监控后台的服务器，一旦发现故障机就将其踢出集群。并且对于上下行的数据进行过滤，对非法 IP 限流，这些都是代理服务器的工作。
- `缓存代理`。将内容缓存到代理服务器，使得客户端可以直接从代理服务器获得而不用到源服务器那里。

### 相关头部字段

**Via**

代理服务器需要标明自己的身份，在 HTTP 传输中留下自己的痕迹，怎么办呢？

通过`Via`字段来记录。举个例子，现在中间有两台代理服务器，在客户端发送请求后会经历这样一个过程:

```
客户端 -> 代理1 -> 代理2 -> 源服务器
```

在源服务器收到请求后，会在`请求头`拿到这个字段:

```
Via: proxy_server1, proxy_server2
```

而源服务器响应时，最终在客户端会拿到这样的`响应头`:

```
Via: proxy_server2, proxy_server1
```

可以看到，`Via`中代理的顺序即为在 HTTP 传输中报文传达的顺序。

**X-Forwarded-For**

字面意思就是`为谁转发`, 它记录的是`请求方`的`IP`地址(注意，和`Via`区分开，`X-Forwarded-For`记录的是请求方这一个IP)。

**X-Real-IP**

是一种获取用户真实 IP 的字段，不管中间经过多少代理，这个字段始终记录最初的客户端的IP。

相应的，还有`X-Forwarded-Host`和`X-Forwarded-Proto`，分别记录`客户端`(注意哦，不包括代理)的`域名`和`协议名`。

### X-Forwarded-For产生的问题

前面可以看到，`X-Forwarded-For`这个字段记录的是请求方的 IP，这意味着每经过一个不同的代理，这个字段的名字都要变，从`客户端`到`代理1`，这个字段是客户端的 IP，从`代理1`到`代理2`，这个字段就变为了代理1的 IP。

但是这会产生两个问题:

- 意味着代理必须解析 HTTP 请求头，然后修改，比直接转发数据性能下降。
- 在 HTTPS 通信加密的过程中，原始报文是不允许修改的。

由此产生了`代理协议`，一般使用明文版本，只需要在 HTTP 请求行上面加上这样格式的文本即可:

```
// PROXY + TCP4/TCP6 + 请求方地址 + 接收方地址 + 请求端口 + 接收端口
PROXY TCP4 1 2 1111 2222
GET / HTTP/1
...
```

这样就可以解决`X-Forwarded-For`带来的问题了。



----

## 61. HTTP1.1 中如何解决 HTTP 的队头阻塞问题？

### 什么是 HTTP 队头阻塞？

HTTP 传输是基于`请求-应答`的模式进行的，**报文必须是一发一收**，但值得注意的是，里面的任务被放在一个任务队列中串行执行，一旦队首的请求处理太慢，就会阻塞后面请求的处理。这就是著名的 **HTTP队头阻塞** 问题。

### 并发连接

对于一个域名允许分配多个长连接，那么相当于增加了任务队列，不至于一个队伍的任务阻塞其它所有任务。在RFC2616规定过客户端最多并发 2 个连接，不过事实上在现在的浏览器标准中，这个上限要多很多，Chrome 中是 6 个。

但其实，即使是提高了并发连接，还是不能满足人们对性能的需求。

### 域名分片

一个域名不是可以并发 6 个长连接吗？那我就多分几个域名。

比如 static1.test.com 、static2.test.com。

这样一个 test.com 域名下可以分出非常多的二级域名，而它们都指向同样的一台服务器，能够并发的长连接数更多了，事实上也更好地解决了队头阻塞的问题。



----

## 62. HTTP 中如何处理表单数据的提交？

在 http 中，有两种主要的表单提交的方式，体现在两种不同的Content-Type取值:

- application/x-www-form-urlencoded
- multipart/form-data

由于表单提交一般是POST请求，很少考虑GET，因此这里我们将默认提交的数据放在请求体中。

### application/x-www-form-urlencoded

对于`application/x-www-form-urlencoded`格式的表单内容，有以下特点:

- 其中的数据会被编码成以&分隔的键值对
- 字符以URL编码方式编码。

如：

```
// 转换过程: {a: 1, b: 2} -> a=1&b=2 -> 如下(最终形式)
"a%3D1%26b%3D2"
```

### multipart/form-data

对于 `multipart/form-data` 而言:

- 请求头中的 `Content-Type` 字段会包含 `boundary` ，且 `boundary` 的值有浏览器默认指定。例: `Content-Type: multipart/form-data;boundary=----WebkitFormBoundaryRRJKeWfHPGrS4LKe`。
- **数据会分为多个部分，每两个部分之间通过分隔符来分隔**，每部分表述均有 HTTP 头部描述子包体，如Content-Type，在最后的分隔符会加上--表示结束。

相应的请求体是下面这样:

```http
Content-Disposition: form-data;name="data1";
Content-Type: text/plain
data1
----WebkitFormBoundaryRRJKeWfHPGrS4LKe
Content-Disposition: form-data;name="data2";
Content-Type: text/plain
data2
----WebkitFormBoundaryRRJKeWfHPGrS4LKe--
```

值得一提的是，`multipart/form-data` 格式最大的特点在于:每一个表单元素都是独立的资源表述。另外，你可能在写业务的过程中，并没有注意到其中还有boundary的存在，如果你打开抓包工具，确实可以看到不同的表单元素被拆分开了，之所以在平时感觉不到，是以为浏览器和 HTTP 给你封装了这一系列操作。

而且，在实际的场景中，对于图片等文件的上传，基本采用`multipart/form-data`而不用`application/x-www-form-urlencoded`，因为没有必要做 URL 编码，带来巨大耗时的同时，也占用了更多的空间。



----

##  63. 对于定长和不定长的数据，HTTP 是怎么传输的？

### 定长包体

对于定长包体而言，发送端在传输的时候一般会带上 `Content-Length`，来指明包体的长度。

### 不定长包体

介绍另外一个 http 头部字段：`Transfer-Encoding: chunked`。

表示分块传输数据，设置这个字段后会自动产生两个效果:

- Content-Length 字段会被忽略
- 基于长连接持续推送动态内容



---

## 64. HTTP 报文结构是怎样的？

对于 TCP 而言，在传输的时候分为两个部分:TCP头和数据部分。

而 HTTP 类似，也是header + body的结构，具体而言:

> 起始行 + 头部 + 空行 + 实体

http 请求报文和响应报文是有一定区别

### 起始行

对于**请求报文**来说，起始行类似下面这样:

> GET /home HTTP/1.1

也就是方法 + 路径 + http版本。

对于**响应报文**来说，起始行一般长这个样:

> HTTP/1.1 200 OK

响应报文的起始行也叫做**状态行**，由http版本、状态码和原因三部分组成。

值得注意的是，在起始行中，**每两个部分之间用空格隔开，最后一个部分后面应该接一个换行**，严格遵循ABNF语法规范。

### 头部

展示一下请求头和响应头在报文中的位置:

![img](E:\pogject\学习笔记\image\http\http报文结构1)



![img](E:\pogject\学习笔记\image\http\http报文结构响应)

不管是请求头还是响应头，其中的字段是相当多的，而且牵扯到http非常多的特性，这里就不一一列举的，重点看看这些头部字段的格式：

- 字段名**不区分大小写**
- 字段名**不允许出现空格**，**不可以出现下划线_**
- 字段名后面必须紧接着冒号 **:**

### 空行

很重要，**用来区分开头部和实体。**

如果说在头部中间故意加一个空行，那么空行后的内容全部被视为实体。

### 实体

就是具体的数据了，也就是body部分。请求报文对应**请求体**, 响应报文对应**响应体**。



----

## 65. 为什么说HTTP是无状态的协议？

因为它的每个请求都是完全独立的，每个请求包含了处理这个请求所需的完整的数据。

**无状态协议**是**指协议对务处理没有记忆能力**。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就较快。 Http协议不像建立了socket连接的两个终端，双方是可以互相通信的，**http的客户端只能通过请求服务器来获取相关内容或文件信息。**

http协议这种特性有优点也有缺点，优点在于解放了服务器，每一次请求“点到为止”不会造成不必要连接占用，缺点在于每次请求会传输大量重复的内容信息。

在同一个连接允许传输多个HTTP请求的情况下，如果第一个请求出错了，后面的请求一般也能够继续处理（当然，如果导致协议解析失败、消息分片错误之类的自然是要除外的）可以看出，这种协议的结构是要比有状态的协议更简单的。



----

## 66. 什么是负载均衡？

客户端发送的、Nginx反向代理服务器接收到的请求数量，就是我们说的**负载量**。请求数量按照一定的规则进行分发到不同的服务器处理的规则，就是一种均衡规则。**将服务器接收到的请求按照规则分发的过程，称为负载均衡。**

负载均衡在实际项目操作过程中，有**硬件负载均衡**和**软件负载均衡**两种。

- 硬件负载均衡也称为硬负载，如F5负载均衡，相对造价昂贵成本较高，但是数据的稳定性安全性等等有非常好的保障，如中国移动、中国联通这样的公司才会选择硬负载进行操作；
- 更多的公司考虑到成本原因，会选择使用软件负载均衡，软件负载均衡是利用现有的技术结合主机硬件实现的一种消息队列分发机制。



----

## 67.  Nginx支持哪些负载均衡调度算法？

- **weight轮询**（默认，常用，具有HA功效！）：接收到的请求按照权重分配到不同的后端服务器，即使在使用过程中，某一台后端服务器宕机，Nginx会自动将该服务器剔除出队列，请求受理情况不会受到任何影响。 这种方式下，可以给不同的后端服务器设置一个权重值(weight)，用于调整不同的服务器上请求的分配率；权重数据越大，被分配到请求的几率越大；该权重值，主要是针对实际工作环境中不同的后端服务器硬件配置进行调整的。
- **ip_hash（常用）**：每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，这也在一定程度上解决了集群部署环境下session共享的问题。
- **fair**：智能调整调度算法，动态的根据后端服务器的请求处理到响应的时间进行均衡分配，响应时间短处理效率高的服务器分配到请求的概率高，响应时间长处理效率低的服务器分配到的请求少；结合了前两者的优点的一种调度算法。但是需要注意的是**Nginx默认不支持fair算法**，如果要使用这种调度算法，请安装upstream_fair模块。
- **url_hash**：按照访问的url的hash结果分配请求，每个请求的url会指向后端固定的某个服务器，可以在Nginx作为静态服务器的情况下提高缓存效率。同样要注意Nginx默认不支持这种调度算法，要使用的话需要安装Nginx的hash软件包。



----

##  68. 正向代理和反向代理分别是什么？

说到代理，首先我们要明确一个概念，所谓代理就是一个代表、一个渠道；

此时就涉及到两个角色，一个是被代理角色，一个是目标角色，被代理角色通过这个代理访问目标角色完成一些任务的过程称为代理操作过程；如同生活中的专卖店~客人到adidas专卖店买了一双鞋，这个专卖店就是代理，被代理角色就是adidas厂家，目标角色就是用户。

### 正向代理

正向代理也是大家最常接触的到的代理模式。

在如今的网络环境下，我们如果由于技术需要要去访问国外的某些网站，此时你会发现位于国外的某网站我们通过浏览器是没有办法访问的，此时大家可能都会用一个代理工具进行访问，这个代理工具就是找到一个可以访问国外网站的代理服务器，我们将请求发送给代理服务器，代理服务器去访问国外的网站，然后将访问到的数据传递给我们！

上述这样的代理模式称为正向代理，正向代理最大的特点是客户端非常明确要访问的服务器地址；服务器只清楚请求来自哪个代理服务器，而不清楚来自哪个具体的客户端；正向代理模式屏蔽或者隐藏了真实客户端信息。

总结来说：**正向代理，"它代理的是客户端，代客户端发出请求"**，是一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端必须要进行一些特别的设置才能使用正向代理。

正向代理的用途：

- 访问原来无法访问的资源，如Google
- 可以做缓存，加速访问资源
- 对客户端访问授权，上网进行认证
- 代理可以记录用户访问记录（上网行为管理），对外隐藏用户信息

### 反向代理

明白了什么是正向代理，我们继续看关于反向代理的处理方式。

例如某宝网站，每天同时连接到网站的访问人数已经爆表，单个服务器远远不能满足人民日益增长的购买欲望了，此时就出现了一个大家耳熟能详的名词：分布式部署；

也就是通过部署多台服务器来解决访问人数限制的问题；某宝网站中大部分功能也是直接使用Nginx进行反向代理实现的，并且通过封装Nginx和其他的组件之后起了个高大上的名字：Tengine，有兴趣的童鞋可以访问Tengine的官网查看具体的信息：http://tengine.taobao.org/。

多个客户端给服务器发送的请求，Nginx服务器接收到之后，按照一定的规则分发给了后端的业务处理服务器进行处理了。此时，**请求的来源（也就是客户端）是明确的，但是请求具体由哪台服务器处理的并不明确了**，**Nginx扮演的就是一个反向代理角色**。

客户端是无感知代理的存在的，**反向代理对外都是透明的**，访问者并不知道自己访问的是一个代理。因为客户端不需要任何配置就可以访问。

**反向代理，"它代理的是服务端，代服务端接收请求"，**主要用于服务器集群分布式部署的情况下，反向代理隐藏了服务器的信息。

反向代理的作用：

- 保证内网的安全，通常将反向代理作为公网访问地址，Web服务器是内网
- 负载均衡，通过反向代理服务器来优化网站的负载



---

##  69. nginx是什么？

**Nginx的产生**

没有听过Nginx？那么一定听过它的"同行"Apache吧！Nginx同Apache一样都是一种WEB服务器，基于REST架构风格，以统一资源描述符(Uniform Resources Identifier)URI或者统一资源定位符(Uniform Resources Locator)URL作为沟通依据，通过HTTP协议提供各种网络服务。

然而，这些服务器在设计之初受到当时环境的局限，例如当时的用户规模，网络带宽，产品特点等局限并且各自的定位和发展都不尽相同。这也使得各个WEB服务器有着各自鲜明的特点。

Apache的发展时期很长，而且是毫无争议的世界第一大服务器。它有着很多优点：稳定、开源、跨平台等等。它出现的时间太长了，它兴起的年代，互联网产业远远比不上现在。所以它被设计为一个重量级的。**它是不支持高并发的服务器**。在Apache上运行数以万计的并发访问，会导致服务器消耗大量内存。操作系统对其进行进程或线程间的切换也消耗了大量的CPU资源，导致HTTP请求的平均响应速度降低。

这些都决定了Apache不可能成为高性能WEB服务器，轻量级高并发服务器Nginx就应运而生了。

俄罗斯的工程师Igor Sysoev，他在为Rambler Media工作期间，使用C语言开发了Nginx。Nginx作为WEB服务器一直为Rambler Media提供出色而又稳定的服务。然后呢，Igor Sysoev将Nginx代码开源，并且赋予自由软件许可证。

**Nginx的用途**

**Nginx是一款自由的、开源的、高性能的HTTP服务器和反向代理服务器**；同时也是一个IMAP、POP3、SMTP代理服务器；Nginx可以作为一个HTTP服务器进行网站的发布处理，另外Nginx可以作为反向代理进行负载均衡的实现。



---

## 70. 什么是对象存储OSS？

对象存储OSS（Object Storage Service）是一种海量、安全、低成本、高持久的云存储服务。

OSS具有与平台无关的RESTful API接口，您可以在任何应用、任何时间、任何地点存储和访问任意类型的数据。

- **存储类型**（Storage Class） OSS提供标准、低频访问、归档、冷归档四种存储类型，全面覆盖从热到冷的各种数据存储场景。其中标准存储类型提供高持久、高可用、高性能的对象存储服务，能够支持频繁的数据访问；低频访问存储类型适合长期保存不经常访问的数据（平均每月访问频率1到2次），存储单价低于标准类型；归档存储类型适合需要长期保存（建议半年以上）的归档数据；冷归档存储适合需要超长时间存放的极冷数据。
- **存储空间**（Bucket） 存储空间是您用于存储对象（Object）的容器，所有的对象都必须隶属于某个存储空间。存储空间具有各种配置属性，包括地域、访问权限、存储类型等。您可以根据实际需求，创建不同类型的存储空间来存储不同的数据。
- **对象**（Object） 对象是OSS存储数据的基本单元，也被称为OSS的文件。对象由元信息（Object Meta）、用户数据（Data）和文件名（Key）组成。对象由存储空间内部唯一的Key来标识。对象元信息是一组键值对，表示了对象的一些属性，例如最后修改时间、大小等信息，同时可以在元信息中存储一些自定义的信息。
- **地域**（Region） 地域表示OSS的数据中心所在物理位置。您可以根据费用、请求来源等选择合适的地域创建Bucket。更多信息，请参见OSS已开通的地域。
- **访问域名**（Endpoint） Endpoint表示OSS对外服务的访问域名。OSS以HTTP RESTful API的形式对外提供服务，当访问不同地域的时候，需要不同的域名。通过内网和外网访问同一个地域所需要的域名也是不同的。
- **访问密钥**（AccessKey） AccessKey简称AK，指的是访问身份验证中用到的AccessKey ID和AccessKey Secret。OSS通过使用AccessKey ID和AccessKey Secret对称加密的方法来验证某个请求的发送者身份。AccessKey ID用于标识用户；AccessKey Secret是用户用于加密签名字符串和OSS用来验证签名字符串的密钥，必须保密。

---

## 71. HTTP的长连接和短连接分别是什么？keep-alive是干什么的

`HTTP`的长连接和短连接实际上是`TCP`的长连接和短连接，`HTTP`属于应用层协议。
**短连接：**浏览器和服务器每进行一次`HTPP`操作，就建立一个连接，但任务结束就会中断这个连接
**长连接：**`HTTP1.1`规定了默认保持长连接，也称为持久连接。意思就是，数据传输完成了保持`TCP`连接不断开（不发`RST`包、不四次握手），等待在同域名下继续用这个通道传输数据。
**长连接好处:**

1. 同一个客户端可以使用这个长连接处理其他请求，避免`HTTP`重新连接和断开所消耗的时间；
2. 服务器可以利用这个连接 **主动推送** 消息到客户端（重要的）。

`HTTP`头部有`了Connection: Keep-Alive`这个值，代表客户端期望这次请求是长连接的。但是并不代表一定会使用长连接，服务器端都可以无视这个值，也就是不按标准来。**实现长连接要客户端和服务端都支持长连接。**
`keep-alive`的优点：

- 较少的`CPU`和内存的使用（由于同时打开的连接的减少了）
- 允许请求和应答的`HTTP`管线化
- 降低拥塞控制 （`TCP`连接减少了）
- 减少了后续请求的延迟（无需再进行握手）
- 报告错误无需关闭`TCP`连接

---

## 72. URI、URL、URN分别是什么？

URL代表资源的路径地址，而URI代表资源的名称。

- URI: Universal Resource Identifier 统一资源标志符
- URL: Universal Resource Locator 统一资源定位符 URL类似于住址，它告诉你一种寻找目标的方式(在这个例子中，是通过街道地址找到一个人)。要知道，上述定义同时也是一个URI。
- URN: Universal Resource Name 统一资源名称 我们可以把一个人的名字看作是URN;因此可以用URN来唯一标识一个实体

URL是URI的一个子集，告诉我们访问网络位置的方式

URN是URI的子集，包括名字(给定的命名空间内)，但是不包括访问方式

URN 和 URL 都是URI的子集。

